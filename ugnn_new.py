# -*- coding: utf-8 -*-
"""ugnn_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P1vlWwkIf7VRiI9p8C0rDQbOhSEX8XjS
"""

!pip install torch_geometric medmnist

import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset, SubsetRandomSampler
from torch.utils.data import Dataset, DataLoader

from torchvision import datasets, transforms
from sklearn.model_selection import KFold, train_test_split
import yaml
import os
from torch_geometric.data import Data

import torch
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import os

import medmnist
from medmnist import INFO, Evaluator
from torchvision import transforms


from torch_geometric.nn import MessagePassing
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
import os
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F


import gzip
import struct

import numpy as np

import torch
import random
import csv
import numpy as np
import psutil
import os
import logging
from datetime import datetime

from sklearn.metrics import precision_recall_fscore_support
from tqdm import tqdm
from collections import Counter
import torch
import numpy as np
from sklearn.metrics import precision_recall_fscore_support


from tqdm import tqdm

import torch
from torch.utils.data import random_split


import os
import torch
from torch.utils.data import Dataset
from medmnist.dataset import DermaMNIST, BloodMNIST, BreastMNIST, PneumoniaMNIST, OCTMNIST, PathMNIST


def _load_uint8(f):
    idx_dtype, ndim = struct.unpack('BBBB', f.read(4))[2:]
    shape = struct.unpack('>' + 'I' * ndim, f.read(4 * ndim))
    buffer_length = int(np.prod(shape))
    data = np.frombuffer(f.read(buffer_length), dtype=np.uint8).reshape(shape)
    return data


def _save_uint8(data, f):
    data = np.asarray(data, dtype=np.uint8)
    f.write(struct.pack('BBBB', 0, 0, 0x08, data.ndim))
    f.write(struct.pack('>' + 'I' * data.ndim, *data.shape))
    f.write(data.tobytes())


def save_idx(data: np.ndarray, path: str):
    """Writes an array to disk in IDX format.

    Parameters
    ----------
    data : array_like
        Input array of dtype ``uint8`` (will be coerced if different dtype).
    path : str
        Path of the output file. Will compress with `gzip` if path ends in '.gz'.

    References
    ----------
    http://yann.lecun.com/exdb/mnist/
    """
    open_fcn = gzip.open if path.endswith('.gz') else open
    with open_fcn(path, 'wb') as f:
        _save_uint8(data, f)


def load_idx(path: str) -> np.ndarray:
    """Reads an array in IDX format from disk.

    Parameters
    ----------
    path : str
        Path of the input file. Will uncompress with `gzip` if path ends in '.gz'.

    Returns
    -------
    np.ndarray
        Output array of dtype ``uint8``.

    References
    ----------
    http://yann.lecun.com/exdb/mnist/
    """
    open_fcn = gzip.open if path.endswith('.gz') else open
    with open_fcn(path, 'rb') as f:
        return _load_uint8(f)



def set_seed(seed):
    torch.manual_seed(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

def count_learnable_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def get_memory_usage():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / (1024 * 1024)  # Convert to MB

def write_performance_to_file(mlp_performances, gnn_performances, fold):
    # Write MLP performances
    with open(f'mlp_performance_fold_{fold}.csv', 'w', newline='') as csvfile:
        fieldnames = ['fold', 'mlp_idx', 'precision', 'recall', 'f1']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for perf in mlp_performances:
            if perf['fold'] == fold:
                writer.writerow(perf)

    # Write GNN performances
    with open(f'gnn_performance_fold_{fold}.csv', 'w', newline='') as csvfile:
        fieldnames = ['fold', 'mlp_idx', 'precision', 'recall', 'f1']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for perf in gnn_performances:
            if perf['fold'] == fold:
                writer.writerow(perf)


def count_learnable_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def create_dir_if_not_exists(dir_path: str) -> None:
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

# del logger
logger = logging.getLogger()
logger.handlers.clear()

log_dir = f'logs'
create_dir_if_not_exists(log_dir)

# Create the log file path
log_file = os.path.join(log_dir, f'{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.log')

# Configure the logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Create file handler
file_handler = logging.FileHandler(log_file)
file_handler.setLevel(logging.INFO)

# Create stream handler for console output
stream_handler = logging.StreamHandler()
stream_handler.setLevel(logging.INFO)

# Create formatter and add it to the handlers
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
stream_handler.setFormatter(formatter)

# Add the handlers to the logger
logger.addHandler(file_handler)
logger.addHandler(stream_handler)

fold = 2
seeds = [42, 1773, 7]
seed = seeds[fold]
set_seed(seed)

logger.info(f"{fold}, {seed}")

from google.colab import drive
drive.mount('/content/drive')

prefix = "drive/MyDrive"

class MNISTLike(Dataset):
    def __init__(self, root_dir, split: str, val_size=0.2, transform=None):
        self.root_dir = root_dir
        prefix = "train" if split in ["train", "val"] else "t10k"

        images_filename = prefix + "-images-idx3-ubyte.gz"
        labels_filename = prefix + "-labels-idx1-ubyte.gz"
        pert_filename = prefix + "-pert-idx1-ubyte.gz"

        # Load data
        self.images = torch.from_numpy(load_idx(os.path.join(self.root_dir, images_filename)))
        self.labels = torch.from_numpy(load_idx(os.path.join(self.root_dir, labels_filename)))
        self.perts = torch.from_numpy(load_idx(os.path.join(self.root_dir, pert_filename)))

        # Ensure all tensors have matching lengths
        assert len(self.images) == len(self.labels) == len(self.perts), "Data lengths do not match"

        num_samples = self.images.size(0)
        num_val_samples = int(val_size * num_samples)
        num_train_samples = num_samples - num_val_samples


        train_val_gen = torch.Generator()
        train_val_gen.manual_seed(seed)


        # Randomly shuffle indices for train-val split
        indices = torch.randperm(num_samples, generator=train_val_gen)
        train_indices = indices[:num_train_samples]
        val_indices = indices[num_train_samples:]

        logger.info(split)
        logger.info(train_indices)
        logger.info(val_indices)

        # Subset data for train or validation
        if split == "train":
            self.images = self.images[train_indices]
            self.labels = self.labels[train_indices]
            self.perts = self.perts[train_indices]
        elif split == "val":
            self.images = self.images[val_indices]
            self.labels = self.labels[val_indices]
            self.perts = self.perts[val_indices]

        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # Normalize the image to [0, 1]
        image = self.images[idx].float().unsqueeze(0) / 255.0
        label = self.labels[idx]
        pert = self.perts[idx]

        # Apply optional transformations
        if self.transform:
            image = self.transform(image)

        return image, label, pert


class MorphoMNISTDistShiftDataset(Dataset):
    def __init__(self, dataset, perturbation_to_model):
        self.dataset = dataset
        self.perturbation_to_model = perturbation_to_model

        # Create a mapping from MLP index to list of indices in the dataset
        self.model_to_indices = {}
        for idx, pert in enumerate(self.dataset.perts):
            pert = pert.item()
            if pert in self.perturbation_to_model:
                model_idx = self.perturbation_to_model[pert]
                if model_idx not in self.model_to_indices:
                    self.model_to_indices[model_idx] = []
                self.model_to_indices[model_idx].append(idx)

        for model_idx, indices in self.model_to_indices.items():
            logger.info(f"Model: {model_idx}, len_ind: {len(indices)}")

        # Determine the length of the dataset (minimum among the MLP datasets)
        self.length = min(len(indices) for indices in self.model_to_indices.values())

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        batch = {}
        for model_idx, indices in self.model_to_indices.items():
            data_idx = indices[idx % len(indices)]  # Use modulo to avoid IndexError
            image, label, pert = self.dataset[data_idx]
            batch[model_idx] = (image, label)
        return batch

# Step 3: Custom Collate Function
def multi_mlp_collate_fn(batch):
    collated_batch = {}
    mlp_indices = batch[0].keys()

    for model_idx in mlp_indices:
        images = []
        labels = []
        for item in batch:
            image, label = item[model_idx]
            images.append(image)
            labels.append(label)
        images = torch.stack(images)
        labels = torch.tensor(labels)
        collated_batch[model_idx] = (images, labels)
    return collated_batch


# Base class for filtering dataset by perturbation level
class PerturbationDataset(Dataset):
    def __init__(self, dataset, perturbation_levels):
        """
        Parameters:
        - dataset: An instance of MNISTLike dataset.
        - perturbation_levels: A list of perturbation levels to include.
        """
        self.dataset = dataset
        self.perturbation_levels = perturbation_levels

        # Filter indices based on perturbation levels
        self.indices = [idx for idx, pert in enumerate(self.dataset.perts) if pert.item() in self.perturbation_levels]

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        data_idx = self.indices[idx]
        image, label, pert = self.dataset[data_idx]
        return image, label, pert

# Dataset for perturbation 0
class Pert0Dataset(PerturbationDataset):
    def __init__(self, dataset):
        super().__init__(dataset, perturbation_levels=[0])

# Dataset for perturbation 1
class Pert1Dataset(PerturbationDataset):
    def __init__(self, dataset):
        super().__init__(dataset, perturbation_levels=[1])

# Dataset for perturbation 2
class Pert2Dataset(PerturbationDataset):
    def __init__(self, dataset):
        super().__init__(dataset, perturbation_levels=[2])

# Mixed dataset where any perturbation can come randomly
class MixedPerturbationDataset(Dataset):
    def __init__(self, dataset):
        self.dataset = dataset
        self.indices = list(range(len(self.dataset)))  # Include all indices
        # Shuffle the indices to ensure randomness
        self.indices = torch.randperm(len(self.indices)).tolist()

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        data_idx = self.indices[idx]
        image, label, pert = self.dataset[data_idx]
        return image, label

class MedMNISTDistShift(Dataset):
    def __init__(self, dataset, cluster_to_indices):
        """
        dataset: Temel olarak MNISTLike benzeri bir dataset. Bu dataset __getitem__ ile (image, label, pert) döndürüyor.
        cluster_to_indices: Her cluster için indeksleri tutan bir sözlük.
            Örn:
            {
                0: [2, 5, 10, 11, ...],  # Cluster 0'a ait örneklerin indeksleri
                1: [0, 1, 7, 9, ...]     # Cluster 1'e ait örneklerin indeksleri
            }

        Bu sayede farklı cluster'lar UGNN içinde farklı "model" olarak ele alınabilir.
        """

        self.dataset = dataset
        self.model_to_indices = cluster_to_indices  # cluster_to_indices'i direkt model_to_indices olarak kullanıyoruz

        # Bilgilendirme çıktıları
        for model_idx, indices in self.model_to_indices.items():
            logger.info(f"Model (Cluster): {model_idx}, len_ind: {len(indices)}")

        # Her cluster (model) için eldeki minimum örnek sayısını belirle
        self.length = min(len(indices) for indices in self.model_to_indices.values())

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        """
        Her çağrıldığında, her model (cluster) için o cluster'a ait indekslerden bir örnek seçer.
        idx değeri örnek sayısını aştığında modulo kullanarak tekrara düşmemizi sağlar.
        """
        batch = {}
        for model_idx, indices in self.model_to_indices.items():
            data_idx = indices[idx % len(indices)]  # Modulo ile indeksin taşması engellenir
            image, label = self.dataset[data_idx]

            batch[model_idx] = (image, label)
        return batch

data_transform = data_transform = transforms.Compose([
    transforms.ToTensor(),
    # transforms.Grayscale(num_output_channels=1),
    transforms.Normalize(mean=[.5], std=[.5])
])

med_mnist_tr = PathMNIST(split="train", download=True, transform=data_transform, target_transform=lambda x: torch.tensor(x[0], dtype=torch.long))
med_mnist_val = PathMNIST(split="val", download=True, transform=data_transform, target_transform=lambda x: torch.tensor(x[0], dtype=torch.long))
med_mnist_test = PathMNIST(split="test", download=True, transform=data_transform, target_transform=lambda x: torch.tensor(x[0], dtype=torch.long))
len(med_mnist_tr), len(med_mnist_val), len(med_mnist_test)

num_clusters = 3

cluster_to_indices = {}
for cluster_idx in range(num_clusters):
    cluster_to_indices[cluster_idx] = np.load(f"PathMNIST_cluster{cluster_idx}.npy")
    print(f"Cluster {cluster_idx}: {len(cluster_to_indices[cluster_idx])} samples")

cluster_to_indices

med_mnist_dist_shift_tr = MedMNISTDistShift(med_mnist_tr, cluster_to_indices)

med_mnist_dist_shift_tr[234][1][1], med_mnist_dist_shift_tr[234][1][0].shape

class ScaledTanh(nn.Module):
    def __init__(self, scale=1.0):
        super(ScaledTanh, self).__init__()
        self.scale = scale

    def forward(self, input):
        return self.scale * torch.tanh(input / self.scale)

class ScaledSoftsign(nn.Module):
    def __init__(self, scale=1.0):
        super(ScaledSoftsign, self).__init__()
        self.scale = scale

    def forward(self, input):
        return self.scale * input / (self.scale + input.abs())

import math


class MLPClassifier(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, name=None, generator=None):
        super(MLPClassifier, self).__init__()

        # Create the layers
        layers = []
        in_size = input_size
        for h_size in hidden_sizes:
            layers.append(nn.Linear(in_size, h_size))
            layers.append(nn.ReLU())
            in_size = h_size
        layers.append(nn.Linear(in_size, output_size))
        self.net = nn.Sequential(*layers)

        # Set name
        if name is None:
            self.name = f"{len(hidden_sizes) + 1}-layer{'-'.join(str(hidden_size) for hidden_size in hidden_sizes)}"
        else:
            self.name = name

        # Apply custom initialization
        self._initialize_weights(generator)

    def _initialize_weights(self, generator):
        for module in self.net:
            if isinstance(module, nn.Linear):
                # Apply Kaiming initialization for weights
                nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5), nonlinearity='relu', generator=generator)

                # Initialize biases to zero
                if module.bias is not None:
                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)
                    bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
                    nn.init.uniform_(module.bias, -bound, bound, generator=generator)

    def forward(self, x):
        return self.net(x.flatten(1, -1))

    def __repr__(self):
        return self.name

    def __str__(self):
        return self.name

    def load_weights_from_graph(mlp, data, layer_metadata):
        """
        Loads weights and biases from the combined graph into the given MLP.

        Args:
            mlp: The target MLP model to load weights into.
            data: The combined graph data containing edge_attr, edge_index, and biases.
            layer_metadata: Metadata about the layers in the MLP within the combined graph.
        """
        for layer, meta in zip(mlp.net, layer_metadata):
            if meta['layer_type'] == 'linear':
                # Extract weights
                weight_matrix = torch.zeros((meta['out_features'], meta['in_features']))
                input_nodes = meta['input_nodes']
                output_nodes = meta['output_nodes']

                input_node_to_idx = {node: idx for idx, node in enumerate(input_nodes)}
                output_node_to_idx = {node: idx for idx, node in enumerate(output_nodes)}

                # Iterate over edges in the combined graph
                for edge_idx in range(data.edge_index.size(1)):
                    src, tgt = data.edge_index[:, edge_idx].tolist()
                    if src in input_node_to_idx and tgt in output_node_to_idx:
                        src_idx = input_node_to_idx[src]
                        tgt_idx = output_node_to_idx[tgt]
                        weight_matrix[tgt_idx, src_idx] = data.edge_attr[edge_idx]

                # Assign weights to the layer
                layer.weight.data = weight_matrix

                # Extract and assign biases
                bias_vector = torch.tensor([data.bias[node] for node in output_nodes])
                layer.bias.data = bias_vector


class CNNClassifier(nn.Module):
    def __init__(self, in_channels=1, num_classes=10, name=None, generator=None):
        super(CNNClassifier, self).__init__()
        self.in_channels = in_channels
        self.kernel_size = (3, 3)
        self.net = nn.Sequential(
            nn.Conv2d(in_channels, 4, kernel_size=self.kernel_size, stride=1, padding=1),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(4*28*28, num_classes)
        )

        self._initialize_weights(generator)


        # Generate a name if not provided
        if name is None:
            layer_info = []
            for layer in self.net:
                if isinstance(layer, nn.Conv2d):
                    layer_info.append(f"Conv({layer.in_channels}->{layer.out_channels}, {layer.kernel_size[0]}x{layer.kernel_size[1]})")
                elif isinstance(layer, nn.Linear):
                    layer_info.append(f"Linear({layer.in_features}->{layer.out_features})")
            self.name = f"SimpleCNN-{len(layer_info)}-layers: " + " -> ".join(layer_info)
        else:
            self.name = name

    def forward(self, x):
        return self.net(x)

    def _initialize_weights(self, generator=None):
        """
        Custom weight initialization for CNN layers.
        Applies Kaiming initialization for Conv2d layers and sets biases to zero.

        Args:
            generator: Random number generator for reproducibility (optional).
        """
        for module in self.net:
            if isinstance(module, nn.Conv2d):
                n = self.in_channels
                for k in self.kernel_size:
                    n *= k
                stdv = 1. / math.sqrt(n)
                module.weight.data.uniform_(-stdv, stdv, generator=generator)
                if module.bias is not None:
                    module.bias.data.uniform_(-stdv, stdv, generator=generator)
            elif isinstance(module, nn.Linear):
                # Apply Kaiming initialization for Linear layers as well
                nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5), nonlinearity='relu', generator=generator)
                if module.bias is not None:
                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)
                    bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
                    nn.init.uniform_(module.bias, -bound, bound, generator=generator)

    def __repr__(self):
        return self.name

    def __str__(self):
        return self.name


class CNNClassifierDeep(nn.Module):
    def __init__(self, in_channels=3, num_classes=10, name=None, generator=None):
        super(CNNClassifierDeep, self).__init__()
        self.in_channels = in_channels
        self.kernel_size = (3, 3)
        self.net = nn.Sequential(
            # Layer 1: Feature extraction + downsampling (stride > 1)
            nn.Conv2d(in_channels, 4, kernel_size=self.kernel_size, stride=2, padding=1),
            nn.ReLU(),
            # 14
            nn.Conv2d(4, 8, kernel_size=self.kernel_size, stride=2, padding=1),
            nn.ReLU(),
            # 7
            nn.Conv2d(8, 8, kernel_size=self.kernel_size, stride=2, padding=1),
            nn.ReLU(),
            # 4
            nn.Flatten(),
            # Fully connected layer
            nn.Linear(4*4*8, num_classes)  # Adjust input size based on feature map size
        )

        self._initialize_weights(generator)


        # Generate a name if not provided
        if name is None:
            layer_info = []
            for layer in self.net:
                if isinstance(layer, nn.Conv2d):
                    layer_info.append(f"Conv({layer.in_channels}->{layer.out_channels}, {layer.kernel_size[0]}x{layer.kernel_size[1]})")
                elif isinstance(layer, nn.Linear):
                    layer_info.append(f"Linear({layer.in_features}->{layer.out_features})")
            self.name = f"SimpleCNN-{len(layer_info)}-layers: " + " -> ".join(layer_info)
        else:
            self.name = name

    def forward(self, x):
        return self.net(x)

    def _initialize_weights(self, generator=None):
        """
        Custom weight initialization for CNN layers.
        Applies Kaiming initialization for Conv2d layers and sets biases to zero.

        Args:
            generator: Random number generator for reproducibility (optional).
        """
        for module in self.net:
            if isinstance(module, nn.Conv2d):
                n = self.in_channels
                for k in self.kernel_size:
                    n *= k
                stdv = 1. / math.sqrt(n)
                module.weight.data.uniform_(-stdv, stdv, generator=generator)
                if module.bias is not None:
                    module.bias.data.uniform_(-stdv, stdv, generator=generator)
            elif isinstance(module, nn.Linear):
                # Apply Kaiming initialization for Linear layers as well
                nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5), nonlinearity='relu', generator=generator)
                if module.bias is not None:
                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)
                    bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
                    nn.init.uniform_(module.bias, -bound, bound, generator=generator)

    def __repr__(self):
        return self.name

    def __str__(self):
        return self.name

class UGNN(MessagePassing):
    def __init__(
        self,
        data,
        layer_neurons_lists,
        input_indices_list,
        model2cluster,
        device,
        k_edge_theta,
        k_bias_theta,
        act: str,
        scale,
        name=None,
    ):
        super(UGNN, self).__init__(aggr=None)
        self.data = data
        self.layer_neurons_lists = layer_neurons_lists
        self.input_indices_list = input_indices_list
        self.model2cluster = model2cluster
        self.activations = data.activation.to(device)
        self.edge_index = data.edge_index.to(device)
        self.device = device
        self.scale = scale

        self.generator = torch.Generator(device=device)
        self.generator.manual_seed(seed)


        self.register_buffer("edge_attr", data.edge_attr.clone().to(device))
        self.register_buffer("biases", data.bias.clone().to(device))

        self.k_edge_theta = min(data.edge_attr.size(0), k_edge_theta)

        self.k_bias_theta = min(
            data.num_nodes
            - sum(len(input_nodes) for input_nodes in self.input_indices_list),
            k_bias_theta,
        )

        self.theta_edge = nn.Parameter(torch.ones(self.k_edge_theta, device=device))
        self.theta_bias = nn.Parameter(torch.ones(self.k_bias_theta, device=device))
        self.theta_edge_shift = nn.Parameter(torch.zeros(self.k_edge_theta, device=device))
        self.theta_bias_shift = nn.Parameter(torch.zeros(self.k_bias_theta, device=device))
        self.model_loss_weights = nn.Parameter(torch.ones(len(model2cluster), device=device))
        self.theta_edge_act_scale = nn.Parameter(torch.ones(1, device=device))
        self.theta_bias_act_scale = nn.Parameter(torch.ones(1, device=device))
        self.alpha = nn.Parameter(torch.ones(1, device=device))


        # Optionally, add small random perturbations around 1
        # nn.init.normal_(self.theta_edge, mean=1.0, std=0.1, generator=self.generator)
        # nn.init.normal_(self.theta_bias, mean=1.0, std=0.1, generator=self.generator)

        # nn.init.normal_(self.theta_edge_shift, mean=1.0, std=0.01, generator=self.generator)
        # nn.init.normal_(self.theta_bias_shift, mean=1.0, std=0.01, generator=self.generator)
        self.edge_groups = self.random_assign_edge_groups()
        self.bias_groups = self.random_assign_bias_groups()

        activation_functions = {
            "tanh": nn.Tanh(),
            "relu": nn.ReLU(),
            "sigmoid": nn.Sigmoid(),
            "leaky_relu": nn.LeakyReLU(),
            "identity": nn.Identity(),
            "softsign": nn.Softsign(),
            "scaled_tanh": ScaledTanh(self.scale),
            "scaled_softsign": ScaledSoftsign(self.scale),
        }

        if act in activation_functions:
            self.act = activation_functions[act]
        else:
            raise ValueError(f"Activation function '{act}' is not supported")

        if name is None:
            self.name = (
                f"uGNN-k_edge_theta-{k_edge_theta}-"
                f"k_bias_theta-{k_bias_theta}-"
                f"act-{act}-"
            )
        else:
            self.name = name

        logger.info(self.name)

    def random_assign_edge_groups(self):
        num_edges = self.edge_index.size(1)
        if self.k_edge_theta >= num_edges:
            # Assign each edge to a unique group (no duplicates)
            edge_groups = torch.randperm(
                num_edges, device=self.device, generator=self.generator
            )
            # If k_edge_theta > num_edges, extra group IDs remain unused
        else:
            # Assign random group IDs to edges, with possible duplicates
            edge_groups = torch.randint(
                0,
                self.k_edge_theta,
                (num_edges,),
                device=self.device,
                generator=self.generator,
            )
        logger.info(f"{edge_groups=}")
        return edge_groups

    # def random_assign_bias_groups(self):
    #     return torch.randint(0, self.k_bias_theta, (self.data.num_nodes,), device=self.device)

    def random_assign_bias_groups(self):
        num_nodes = self.data.num_nodes

        # Collect all input node indices
        input_node_indices = []
        for indices in self.input_indices_list:
            input_node_indices.extend(indices)
        input_node_indices = torch.tensor(
            input_node_indices, dtype=torch.long, device=self.device
        )

        # Create a mask for non-input nodes
        non_input_mask = torch.ones(num_nodes, dtype=torch.bool, device=self.device)
        non_input_mask[input_node_indices] = False  # Set input nodes to False

        num_non_input_nodes = non_input_mask.sum().item()

        # Initialize bias_groups with -1 for input nodes
        bias_groups = torch.full((num_nodes,), -1, dtype=torch.long, device=self.device)

        if self.k_bias_theta >= num_non_input_nodes:
            # Assign each non-input node to a unique group (no duplicates)
            bias_group_ids = torch.randperm(
                num_non_input_nodes, device=self.device, generator=self.generator
            )
            bias_groups[non_input_mask] = bias_group_ids
            # If k_bias_theta > num_non_input_nodes, extra group IDs remain unused
        else:
            # Assign random group IDs to non-input nodes, with possible duplicates
            bias_groups[non_input_mask] = torch.randint(
                0,
                self.k_bias_theta,
                (num_non_input_nodes,),
                device=self.device,
                generator=self.generator,
            )

        logger.info(f"{bias_groups=}")

        return bias_groups

    def forward(self, x_batch):
        # x_batch: [ (images, labels), (images, labels), (images, labels)]
        # images: (batch, channel, height, width)
        # labels: (batch, 1) ?

        batch_size = x_batch[0][0].shape[0]
        device = self.device
        num_nodes = self.data.num_nodes

        if self.training:
            updated_edge_attr, updated_biases = self.update_edge_bias()
        else:
            updated_edge_attr, updated_biases = self.edge_attr, self.biases

        # Proceed with the rest of the forward pass
        # Initialize hidden states
        h = torch.zeros(batch_size, num_nodes, 1, device=device)

        for i, input_indices in enumerate(self.input_indices_list):
            h[:, input_indices] = x_batch[self.model2cluster[i]][0].view(batch_size, -1, 1).to(device)

        # h[:, input_neurons] = x_batch.view(batch_size, -1, 1)

        outputs = []
        h_shared = h.clone()

        # For each MLP
        for _, layer_neurons in enumerate(self.layer_neurons_lists):
            h_model = h_shared.clone()

            for l in range(1, len(layer_neurons)):
                current_layer_nodes = layer_neurons[l]

                # Mask edges for the current MLP
                current_layer_nodes_tensor = torch.tensor(
                    current_layer_nodes, device=device
                )
                mask = (
                    self.edge_index[1].unsqueeze(0)
                    == current_layer_nodes_tensor.unsqueeze(1)
                ).any(0)
                edge_index_layer = self.edge_index[:, mask]
                edge_attr_layer = updated_edge_attr[mask]

                # Perform message passing
                h_current = self.propagate(
                    edge_index_layer,
                    x=h_model,
                    edge_weight=edge_attr_layer,
                    batch_size=batch_size,
                )

                # Add updated biases
                biases_current = updated_biases[current_layer_nodes].view(1, -1, 1)
                h_current[:, current_layer_nodes] += biases_current

                # Apply activation
                activation_flags = self.activations[current_layer_nodes]
                act_nodes = activation_flags == 1
                nodes_to_activate = current_layer_nodes_tensor[act_nodes]
                if nodes_to_activate.numel() > 0:
                    h_current[:, nodes_to_activate] = torch.relu(
                        h_current[:, nodes_to_activate]
                    )

                h_model = h_current

            # Extract outputs for the current nodel
            output_nodes = layer_neurons[-1]
            output = h_model[:, output_nodes].squeeze(2)
            outputs.append(output.to(device))

        return outputs  # List of outputs for each MLP

    def message(self, x_j, edge_weight):
        return edge_weight.view(1, -1, 1) * x_j

    def aggregate(self, inputs, index, batch_size):
        num_nodes = self.data.num_nodes
        h_aggregated = torch.zeros(batch_size, num_nodes, 1, device=inputs.device)
        h_aggregated.index_add_(1, index, inputs)
        return h_aggregated

    def update(self, inputs):
        return inputs

    def update_edge_bias(self):
        theta_e = self.theta_edge[self.edge_groups]  # Shape: [num_edges,]
        theta_e_shift = self.theta_edge_shift[self.edge_groups]
        updated_edge_attr = self.scaled_softsign(
            self.theta_edge_act_scale, self.edge_attr * theta_e + theta_e_shift
        )  # Element-wise multiplication

        # Handle biases: exclude input nodes
        valid_bias_mask = self.bias_groups >= 0  # Boolean mask of shape [num_nodes]

        # Prepare updated_biases tensor
        updated_biases = self.biases.clone()

        # Only update biases for nodes with valid bias groups (non-input nodes)
        if valid_bias_mask.any():
            theta_b = self.theta_bias[
                self.bias_groups[valid_bias_mask]
            ]  # Shape: [num_valid_nodes,]
            theta_b_shift = self.theta_bias_shift[
                self.bias_groups[valid_bias_mask]
            ]
            updated_biases[valid_bias_mask] = self.scaled_softsign(
                self.theta_bias_act_scale, self.biases[valid_bias_mask] * theta_b + theta_b_shift
            )

        # For input nodes (bias group -1), biases remain unchanged

        return updated_edge_attr, updated_biases

    def update_buffers(self):
        with torch.no_grad():
            updated_edge_attr, updated_biases = self.update_edge_bias()

            self.edge_attr.copy_(updated_edge_attr)
            self.biases.copy_(updated_biases)

    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__str__()

    def scaled_softsign(self, scale, x):
        return scale * x / (scale + x.abs())





class UGNN_WS(MessagePassing):
    def __init__(
        self,
        data,
        layer_neurons_lists,
        layer_types_lists,
        input_indices_list,
        model2cluster,
        device,
        edge_to_kernel_idx,
        node_to_layer_idx,
        k_edge_theta,
        k_bias_theta,
        act: str,
        scale,
        name=None,
    ):
        super(UGNN_WS, self).__init__(aggr=None)
        self.data = data
        self.layer_neurons_lists = layer_neurons_lists
        self.layer_types_lists = layer_types_lists
        self.input_indices_list = input_indices_list
        self.model2cluster = model2cluster
        self.activations = data.activation.to(device)
        self.edge_index = data.edge_index.to(device)
        self.device = device
        self.scale = scale

        self.edge_to_kernel_idx = edge_to_kernel_idx
        self.node_to_layer_idx = node_to_layer_idx

        self.generator = torch.Generator(device=device)
        self.generator.manual_seed(seed)

        self.register_buffer("edge_attr", data.edge_attr.clone().to(device))
        self.register_buffer("biases", data.bias.clone().to(device))

        # Compute unique kernels
        unique_kernels = set()
        for kernel_info in edge_to_kernel_idx.values():
            if isinstance(kernel_info, tuple):
                # Convolutional layer kernel indices
                kernel_idx = ('conv', kernel_info[0], kernel_info[1], kernel_info[2], kernel_info[3], kernel_info[4])
            else:
                # Linear layer kernel indices
                kernel_idx = ('linear', kernel_info['layer_num'], kernel_info['target_idx'], kernel_info['source_idx'])
            unique_kernels.add(kernel_idx)

        print(unique_kernels)
        total_kernels = len(unique_kernels)

        self.k_edge_theta = min(total_kernels, k_edge_theta)

        self.k_bias_theta = min(
            data.num_nodes
            - sum(len(input_nodes) for input_nodes in self.input_indices_list),
            k_bias_theta,
        )

        # Create shared parameters
        self.theta_edge = nn.Parameter(torch.ones(self.k_edge_theta, device=device))
        self.theta_bias = nn.Parameter(torch.ones(self.k_bias_theta, device=device))
        self.theta_edge_shift = nn.Parameter(torch.zeros(self.k_edge_theta, device=device))
        self.theta_bias_shift = nn.Parameter(torch.zeros(self.k_bias_theta, device=device))
        self.model_loss_weights = nn.Parameter(torch.ones(len(model2cluster), device=device))
        self.theta_edge_act_scale = nn.Parameter(torch.ones(1, device=device))
        self.theta_bias_act_scale = nn.Parameter(torch.ones(1, device=device))
        self.alpha = nn.Parameter(torch.ones(1, device=device))

        # Assign edge and bias groups
        self.edge_groups = self.assign_edge_groups()
        self.bias_groups = self.assign_bias_groups()

        activation_functions = {
            "tanh": nn.Tanh(),
            "relu": nn.ReLU(),
            "sigmoid": nn.Sigmoid(),
            "leaky_relu": nn.LeakyReLU(),
            "identity": nn.Identity(),
            "softsign": nn.Softsign(),
            "scaled_tanh": ScaledTanh(self.scale),
            "scaled_softsign": ScaledSoftsign(self.scale),
        }

        if act in activation_functions:
            self.act = activation_functions[act]
        else:
            raise ValueError(f"Activation function '{act}' is not supported")

        if name is None:
            self.name = (
                f"uGNN-k_edge_theta-{k_edge_theta}-"
                f"k_bias_theta-{k_bias_theta}-"
                f"act-{act}-"
            )
        else:
            self.name = name

        logger.info(self.name)

    def assign_edge_groups(self):
        num_edges = self.edge_index.size(1)
        edge_groups = torch.zeros(num_edges, dtype=torch.long, device=self.device)
        unique_kernels = {}
        kernel_id_counter = 0

        for edge_idx in range(num_edges):
            kernel_info = self.edge_to_kernel_idx[edge_idx]
            if isinstance(kernel_info, tuple):
                # Convolutional layer kernel indices
                kernel_idx = ('conv', kernel_info[0], kernel_info[1], kernel_info[2], kernel_info[3], kernel_info[4])
            else:
                # Linear layer kernel indices
                kernel_idx = ('linear', kernel_info['layer_num'], kernel_info['target_idx'], kernel_info['source_idx'])
            if kernel_idx not in unique_kernels:
                unique_kernels[kernel_idx] = kernel_id_counter
                kernel_id_counter += 1
            edge_groups[edge_idx] = unique_kernels[kernel_idx]

        # Map kernel IDs to group IDs based on k_edge_theta
        total_kernels = len(unique_kernels)
        kernel_ids = list(unique_kernels.values())
        if self.k_edge_theta >= total_kernels:
            kernel_to_group = {k_id: k_id for k_id in kernel_ids}
        else:
            random_generator = torch.Generator(device=self.device)
            random_generator.manual_seed(seed)
            group_assignments = torch.randint(0, self.k_edge_theta, (total_kernels,), generator=random_generator, device=self.device)
            kernel_to_group = {k_id: group_assignments[i].item() for i, k_id in enumerate(kernel_ids)}

        # Assign group IDs to edge_groups
        for edge_idx in range(num_edges):
            kernel_id = edge_groups[edge_idx].item()
            edge_groups[edge_idx] = kernel_to_group[kernel_id]

        logger.info(f"{edge_groups=}")
        return edge_groups

    def assign_bias_groups(self):
        num_nodes = self.data.num_nodes

        # Collect all input node indices
        input_node_indices = []
        for indices in self.input_indices_list:
            input_node_indices.extend(indices)
        input_node_indices = torch.tensor(
            input_node_indices, dtype=torch.long, device=self.device
        )

        # Create a mask for non-input nodes
        non_input_mask = torch.ones(num_nodes, dtype=torch.bool, device=self.device)
        non_input_mask[input_node_indices] = False  # Set input nodes to False

        num_non_input_nodes = non_input_mask.sum().item()

        # Initialize bias_groups with -1 for input nodes
        bias_groups = torch.full((num_nodes,), -1, dtype=torch.long, device=self.device)

        if self.k_bias_theta >= num_non_input_nodes:
            # Assign each non-input node to a unique group (no duplicates)
            bias_group_ids = torch.randperm(
                num_non_input_nodes, device=self.device, generator=self.generator
            )
            bias_groups[non_input_mask] = bias_group_ids
            # If k_bias_theta > num_non_input_nodes, extra group IDs remain unused
        else:
            # Assign random group IDs to non-input nodes, with possible duplicates
            bias_groups[non_input_mask] = torch.randint(
                0,
                self.k_bias_theta,
                (num_non_input_nodes,),
                device=self.device,
                generator=self.generator,
            )

        logger.info(f"{bias_groups=}")

        return bias_groups

    def forward(self, x_batch):
        batch_size = x_batch[0][0].shape[0]
        device = self.device
        num_nodes = self.data.num_nodes

        if self.training:
            updated_edge_attr, updated_biases = self.update_edge_bias()
        else:
            updated_edge_attr, updated_biases = self.edge_attr, self.biases

        # Initialize hidden states
        h = torch.zeros(batch_size, num_nodes, 1, device=device)

        for i, input_indices in enumerate(self.input_indices_list):
            h[:, input_indices] = x_batch[self.model2cluster[i]][0].view(batch_size, -1, 1).to(device)

        outputs = []
        h_shared = h.clone()

        # For each model
        for model_idx, (layer_neurons, layer_types) in enumerate(zip(self.layer_neurons_lists, self.layer_types_lists)):
            h_model = h_shared.clone()

            for l in range(1, len(layer_neurons)):
                current_layer_nodes = layer_neurons[l]
                layer_type = layer_types[l]

                current_layer_nodes_tensor = torch.tensor(
                    current_layer_nodes, device=device
                )
                mask = (
                    self.edge_index[1].unsqueeze(0)
                    == current_layer_nodes_tensor.unsqueeze(1)
                ).any(0)
                edge_index_layer = self.edge_index[:, mask]
                edge_attr_layer = updated_edge_attr[mask]


                # Perform message passing
                h_current = self.propagate(
                    edge_index_layer,
                    x=h_model,
                    edge_weight=edge_attr_layer,
                    batch_size=batch_size,
                )

                # Add updated biases
                biases_current = updated_biases[current_layer_nodes].view(1, -1, 1)
                h_current[:, current_layer_nodes] += biases_current

                # Apply activation
                activation_flags = self.activations[current_layer_nodes]
                act_nodes = activation_flags == 1
                nodes_to_activate = current_layer_nodes_tensor[act_nodes]
                if nodes_to_activate.numel() > 0:
                    h_current[:, nodes_to_activate] = torch.relu(
                        h_current[:, nodes_to_activate]
                    )

                h_model = h_current

            # Extract outputs for the current model
            output_nodes = layer_neurons[-1]
            output = h_model[:, output_nodes].squeeze(2)
            outputs.append(output.to(device))

        return outputs  # List of outputs for each model

    def message(self, x_j, edge_weight):
        return edge_weight.view(1, -1, 1) * x_j

    def aggregate(self, inputs, index, batch_size):
        num_nodes = self.data.num_nodes
        h_aggregated = torch.zeros(batch_size, num_nodes, 1, device=inputs.device)
        h_aggregated.index_add_(1, index, inputs)
        return h_aggregated

    def update(self, inputs):
        return inputs
    def update_edge_bias(self):
        theta_e = self.theta_edge[self.edge_groups]  # Shape: [num_edges,]
        theta_e_shift = self.theta_edge_shift[self.edge_groups]
        updated_edge_attr = self.scaled_softsign(
            self.theta_edge_act_scale, self.edge_attr * theta_e + theta_e_shift
        )  # Element-wise multiplication

        # Handle biases: exclude input nodes
        valid_bias_mask = self.bias_groups >= 0  # Boolean mask of shape [num_nodes]

        # Prepare updated_biases tensor
        updated_biases = self.biases.clone()

        # Only update biases for nodes with valid bias groups (non-input nodes)
        if valid_bias_mask.any():
            theta_b = self.theta_bias[
                self.bias_groups[valid_bias_mask]
            ]  # Shape: [num_valid_nodes,]
            theta_b_shift = self.theta_bias_shift[
                self.bias_groups[valid_bias_mask]
            ]
            updated_biases[valid_bias_mask] = self.scaled_softsign(
                self.theta_bias_act_scale, self.biases[valid_bias_mask] * theta_b + theta_b_shift
            )

        # For input nodes (bias group -1), biases remain unchanged

        return updated_edge_attr, updated_biases

    def update_buffers(self):
        with torch.no_grad():
            updated_edge_attr, updated_biases = self.update_edge_bias()

            self.edge_attr.copy_(updated_edge_attr)
            self.biases.copy_(updated_biases)

    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__str__()

    def scaled_softsign(self, scale, x):
        return scale * x / (scale + x.abs())


class UGNNModelSpecific(MessagePassing):
    def __init__(
        self,
        data,
        node_indices_list,
        layer_neurons_list,
        input_indices_list,
        model2cluster,
        device,
        k_edge_theta,
        k_bias_theta,
        act: str,
        scale,
        name=None,
    ):
        super(UGNNModelSpecific, self).__init__(aggr=None)
        self.data = data
        self.node_indices_list = node_indices_list
        self.layer_neurons_list = layer_neurons_list
        self.input_indices_list = input_indices_list
        self.model2cluster = model2cluster
        self.device = device
        self.scale = scale

        self.num_models = len(self.model2cluster)

        # Aktivasyon fonksiyonu seçimi
        activation_functions = {
            "tanh": nn.Tanh(),
            "relu": nn.ReLU(),
            "sigmoid": nn.Sigmoid(),
            "leaky_relu": nn.LeakyReLU(),
            "identity": nn.Identity(),
            "softsign": nn.Softsign(),
            "scaled_tanh": ScaledTanh(self.scale),
            "scaled_softsign": ScaledSoftsign(self.scale),
        }

        if act in activation_functions:
            self.act = activation_functions[act]
        else:
            raise ValueError(f"Activation function '{act}' is not supported")

        if name is None:
            self.name = f"UGNNModelSpecific-k_edge_theta-{k_edge_theta}-k_bias_theta-{k_bias_theta}-act-{act}-"
        else:
            self.name = name

        # Graf verilerini cihaza al
        self.edge_index = data.edge_index.to(device)
        self.edge_attr = data.edge_attr.to(device)
        self.biases = data.bias.to(device)
        self.activations = data.activation.to(device)

        # Tüm kenarların ve nöronların hangi modele ait olduğunu belirle
        self.edge_model_id = torch.full((self.edge_index.size(1),), -1, dtype=torch.long, device=self.device)
        self.node_model_id = torch.full((data.num_nodes,), -1, dtype=torch.long, device=self.device)

        # Her modelin nöron ve kenarlarını belirleme
        # node_indices_list[model_idx] modeli temsil eden nöron indekslerini tutar
        # layer_neurons_list[model_idx] katman bazında nöron indekslerini tutar
        for m, nodes_of_m in enumerate(self.node_indices_list):
            nodes_of_m = torch.tensor(nodes_of_m, dtype=torch.long, device=self.device)
            self.node_model_id[nodes_of_m] = m

        # Kenarların modele atanması (bir kenar hangi modele ait?)
        # Bir kenarın modeli, edge_index'deki kaynak veya hedef düğümün modeline göre belirlenebilir.
        # Burada basit bir yaklaşım: Kenarın hedef düğümü hangi modeldeyse o modele ait kabul edelim.
        edge_target_nodes = self.edge_index[1]
        self.edge_model_id = self.node_model_id[edge_target_nodes]

        # Her model için kenar ve bias gruplarını ayrı ayrı oluşturacağız
        self.theta_edge_per_model = nn.ParameterList()
        self.theta_bias_per_model = nn.ParameterList()
        self.edge_groups_per_model = []
        self.bias_groups_per_model = []
        self.model_edge_indices = []
        self.model_non_input_nodes = []

        # Input nodelar
        input_nodes_all = torch.cat([torch.tensor(x, device=self.device) for x in self.input_indices_list])
        input_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=self.device)
        input_mask[input_nodes_all] = True

        # Model bazında kenar ve node ayırma
        for m in range(self.num_models):
            # Bu modelin kenarlarını seç
            model_edge_mask = (self.edge_model_id == m)
            model_edge_indices = model_edge_mask.nonzero(as_tuple=True)[0]
            self.model_edge_indices.append(model_edge_indices)

            # Bu modelin nodelarını seç (input hariç)
            model_nodes = torch.tensor(self.node_indices_list[m], device=self.device)
            non_input_mask = ~input_mask[model_nodes]
            model_non_input_nodes = model_nodes[non_input_mask]
            self.model_non_input_nodes.append(model_non_input_nodes)

            num_model_edges = model_edge_indices.numel()
            num_model_non_input_nodes = model_non_input_nodes.numel()

            # Model bazında k_edge_theta ve k_bias_theta hesapla
            k_edge_theta_m = min(num_model_edges, k_edge_theta)
            k_bias_theta_m = min(num_model_non_input_nodes, k_bias_theta)

            # Model için parametreleri oluştur
            theta_edge_m = nn.Parameter(torch.ones(k_edge_theta_m, device=self.device))
            theta_bias_m = nn.Parameter(torch.ones(k_bias_theta_m, device=self.device))

            self.theta_edge_per_model.append(theta_edge_m)
            self.theta_bias_per_model.append(theta_bias_m)

            # Kenar gruplama (model kenarları için rastgele grup atama)
            if k_edge_theta_m > 0 and num_model_edges > 0:
                if k_edge_theta_m >= num_model_edges:
                    # Her kenar için ayrı grup
                    edge_groups_m = torch.randperm(num_model_edges, device=self.device)
                else:
                    edge_groups_m = torch.randint(0, k_edge_theta_m, (num_model_edges,), device=self.device)
            else:
                edge_groups_m = torch.full((num_model_edges,), -1, device=self.device, dtype=torch.long)

            self.edge_groups_per_model.append(edge_groups_m)

            # Bias gruplama (model içindeki non-input nodelar için)
            if k_bias_theta_m > 0 and num_model_non_input_nodes > 0:
                if k_bias_theta_m >= num_model_non_input_nodes:
                    bias_groups_m = torch.randperm(num_model_non_input_nodes, device=self.device)
                else:
                    bias_groups_m = torch.randint(0, k_bias_theta_m, (num_model_non_input_nodes,), device=self.device)
            else:
                bias_groups_m = torch.full((num_model_non_input_nodes,), -1, device=self.device, dtype=torch.long)

            self.bias_groups_per_model.append(bias_groups_m)

        logger.info(self.name)

    def forward(self, x_batch):
        batch_size = x_batch[0][0].shape[0]
        device = self.device
        num_nodes = self.data.num_nodes

        # Güncel kenar ve bias değerlerini hesapla
        updated_edge_attr, updated_biases = self.update_edge_bias()

        # Başlangıç durumları
        h = torch.zeros(batch_size, num_nodes, 1, device=device)

        # Input nodelarını doldur
        for i, input_indices in enumerate(self.input_indices_list):
            h[:, input_indices] = x_batch[self.model2cluster[i]][0].view(batch_size, -1, 1).to(device)

        outputs = []
        h_shared = h.clone()

        # Her model için layer_neurons_list kullanarak ilerle
        # Fakat unify fonksiyonu tüm modelleri tek grafikte birleştirdiğinden,
        # forward adımında aslında tüm düğümler paylaşılan h tablosunda
        # Her modelin son katmanındaki çıkışı alabiliriz.

        # Burada basitçe her modelin son katman nöronlarını alıp output oluşturuyoruz
        for i, layer_neurons in enumerate(self.layer_neurons_list):
            h_model = h_shared

            # Son katman nöronlarını model çıkışı kabul et
            output_nodes = layer_neurons[-1]
            output = h_model[:, output_nodes].squeeze(2)
            outputs.append(output.to(device))

        return outputs  # List of outputs for each model

    def message(self, x_j, edge_weight):
        return edge_weight.view(1, -1, 1) * x_j

    def aggregate(self, inputs, index, batch_size=None):
        num_nodes = self.data.num_nodes
        h_aggregated = torch.zeros(inputs.size(0), num_nodes, 1, device=inputs.device)
        h_aggregated.index_add_(1, index, inputs)
        return h_aggregated

    def update_edge_bias(self):
        # Kenar ve bias güncellemelerini model bazında yap

        updated_edge_attr = self.edge_attr.clone()
        updated_biases = self.biases.clone()

        for m in range(self.num_models):
            model_edge_indices = self.model_edge_indices[m]
            model_non_input_nodes = self.model_non_input_nodes[m]
            edge_groups_m = self.edge_groups_per_model[m]
            bias_groups_m = self.bias_groups_per_model[m]

            # Kenar güncelleme
            if len(edge_groups_m) > 0 and self.theta_edge_per_model[m].numel() > 0:
                theta_e_m = self.theta_edge_per_model[m][edge_groups_m]
                updated_edge_attr[model_edge_indices] = updated_edge_attr[model_edge_indices] * theta_e_m

            # Bias güncelleme
            if len(bias_groups_m) > 0 and self.theta_bias_per_model[m].numel() > 0:
                theta_b_m = self.theta_bias_per_model[m][bias_groups_m]
                updated_biases[model_non_input_nodes] = updated_biases[model_non_input_nodes] * theta_b_m

        return updated_edge_attr, updated_biases


    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__str__()

def mlp_to_graph(mlp):
    neuron_counter = 0
    edge_index = [[], []]  # Source and target nodes
    edge_weight = []       # Edge attributes (weights)
    biases = {}            # Mapping from neuron index to bias
    activations = {}       # Mapping from neuron index to activation function

    # Get the input size from the first Linear layer
    for layer in mlp.net:
        if isinstance(layer, torch.nn.Linear):
            input_size = layer.in_features
            break

    # Create input neurons unique to this MLP
    input_neurons = list(range(neuron_counter, neuron_counter + input_size))
    neuron_counter += input_size
    biases.update({idx: 0.0 for idx in input_neurons})
    activations.update({idx: None for idx in input_neurons})

    prev_layer_neurons = input_neurons
    layer_neurons = [input_neurons]  # Initialize layer_neurons with input layer

    for layer in mlp.net:
        if isinstance(layer, torch.nn.Linear):
            num_neurons = layer.out_features
            curr_layer_neurons = list(range(neuron_counter, neuron_counter + num_neurons))
            neuron_counter += num_neurons

            # Record biases
            bias = layer.bias.data
            for idx, b in zip(curr_layer_neurons, bias):
                biases[idx] = b.item()

            # Record activations (to be set after activation layer)
            for idx in curr_layer_neurons:
                activations[idx] = None  # Placeholder

            # Create edges
            weight_matrix = layer.weight.data  # Shape: [out_features, in_features]
            for target_idx, target_neuron in enumerate(curr_layer_neurons):
                for source_idx, source_neuron in enumerate(prev_layer_neurons):
                    weight = weight_matrix[target_idx, source_idx].item()
                    edge_index[0].append(source_neuron)
                    edge_index[1].append(target_neuron)
                    edge_weight.append(weight)

            prev_layer_neurons = curr_layer_neurons
            layer_neurons.append(curr_layer_neurons)  # Add current layer neurons to layer_neurons

        elif isinstance(layer, torch.nn.ReLU):
            # Set activation function for the previous layer neurons
            for idx in prev_layer_neurons:
                activations[idx] = 'relu'
        else:
            # Handle other layer types if necessary
            pass

    # Convert lists to tensors
    edge_index = torch.tensor(edge_index, dtype=torch.long)
    edge_attr = torch.tensor(edge_weight, dtype=torch.float)

    num_nodes = neuron_counter
    node_bias = torch.zeros(num_nodes, dtype=torch.float)
    for idx, b in biases.items():
        node_bias[idx] = b

    # Activation mapping
    activation_map = {'relu': 1, None: 0}
    node_activation = torch.zeros(num_nodes, dtype=torch.long)
    for idx, act in activations.items():
        node_activation[idx] = activation_map[act]

    # Create the Data object
    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_nodes, name=mlp.name)
    data.bias = node_bias
    data.activation = node_activation

    # Collect all node indices for this MLP
    mlp_node_indices = list(range(num_nodes))

    return data, mlp_node_indices, layer_neurons







def mlp_to_graph_ws(mlp):
    neuron_counter = 0
    edge_index = [[], []]
    edge_weight = []
    biases = {}
    activations = {}
    layer_neurons = []
    edge_to_kernel_idx = {}
    edge_idx_counter = 0
    node_to_layer_idx = {}
    layer_types = []  # Keep track of layer types

    # Get the input size from the first Linear layer
    for layer in mlp.net:
        if isinstance(layer, torch.nn.Linear):
            input_size = layer.in_features
            break

    # Create input neurons unique to this MLP
    input_neurons = list(range(neuron_counter, neuron_counter + input_size))
    neuron_counter += input_size
    biases.update({idx: 0.0 for idx in input_neurons})
    activations.update({idx: None for idx in input_neurons})
    for idx in input_neurons:
        node_to_layer_idx[idx] = 0  # Input layer

    prev_layer_neurons = input_neurons
    layer_neurons = [input_neurons]  # Initialize layer_neurons with input layer
    layer_types.append('input')
    layer_num = 0

    for layer in mlp.net:
        if isinstance(layer, torch.nn.Linear):
            layer_num += 1
            num_neurons = layer.out_features
            curr_layer_neurons = list(range(neuron_counter, neuron_counter + num_neurons))
            neuron_counter += num_neurons

            # Record biases
            bias = layer.bias.data
            for idx, b in zip(curr_layer_neurons, bias):
                biases[idx] = b.item()
                node_to_layer_idx[idx] = layer_num

            # Record activations (to be set after activation layer)
            for idx in curr_layer_neurons:
                activations[idx] = None  # Placeholder

            # Create edges
            weight_matrix = layer.weight.data  # Shape: [out_features, in_features]
            for target_idx, target_neuron in enumerate(curr_layer_neurons):
                for source_idx, source_neuron in enumerate(prev_layer_neurons):
                    weight = weight_matrix[target_idx, source_idx].item()
                    edge_index[0].append(source_neuron)
                    edge_index[1].append(target_neuron)
                    edge_weight.append(weight)  # Store actual weight

                    # Map edge to linear layer indices
                    edge_to_kernel_idx[edge_idx_counter] = {
                        'layer_num': layer_num,
                        'target_idx': target_idx,
                        'source_idx': source_idx
                    }
                    edge_idx_counter += 1

            prev_layer_neurons = curr_layer_neurons
            layer_neurons.append(curr_layer_neurons)  # Add current layer neurons to layer_neurons
            layer_types.append('linear')

        elif isinstance(layer, torch.nn.ReLU):
            # Set activation function for the previous layer neurons
            for idx in prev_layer_neurons:
                activations[idx] = 'relu'
            layer_types.append('relu')
        else:
            # Handle other layer types if necessary
            pass

    # Convert lists to tensors
    edge_index = torch.tensor(edge_index, dtype=torch.long)
    edge_attr = torch.tensor(edge_weight, dtype=torch.float)

    num_nodes = neuron_counter
    node_bias = torch.zeros(num_nodes, dtype=torch.float)
    for idx, b in biases.items():
        node_bias[idx] = b

    # Activation mapping
    activation_map = {'relu': 1, None: 0}
    node_activation = torch.zeros(num_nodes, dtype=torch.long)
    for idx, act in activations.items():
        node_activation[idx] = activation_map[act]

    # Create the Data object
    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_nodes, name=mlp.name)
    data.bias = node_bias
    data.activation = node_activation

    # Collect all node indices for this MLP
    mlp_node_indices = list(range(num_nodes))

    return data, mlp_node_indices, layer_neurons, edge_to_kernel_idx, node_to_layer_idx, layer_types

def cnn_to_graph(cnn, input_shape):
    """
    Converts a CNN into a graph representation suitable for GNN processing.

    Args:
        cnn (nn.Module): The CNN model to convert.
        input_shape (tuple): The shape of the input (C_in, H_in, W_in).

    Returns:
        data (torch_geometric.data.Data): The graph representation.
        cnn_node_indices (list): List of node indices for the CNN.
        layer_neurons (list): List of node indices per layer.
    """
    import torch
    from torch_geometric.data import Data

    neuron_counter = 0
    edge_index = [[], []]
    edge_weight = []
    biases = {}
    activations = {}
    layer_neurons = []
    position_to_node_idx = {}
    current_layer_nodes = []

    C_in, H_in, W_in = input_shape
    device = next(cnn.parameters()).device

    # Create input nodes
    for c_in in range(C_in):
        for i in range(H_in):
            for j in range(W_in):
                node_idx = neuron_counter
                neuron_counter += 1
                current_layer_nodes.append(node_idx)
                position_to_node_idx[('input', c_in, i, j)] = node_idx
                biases[node_idx] = 0.0
                activations[node_idx] = None  # No activation for input nodes

    layer_neurons.append(current_layer_nodes)

    prev_layer_nodes = current_layer_nodes
    prev_layer_type = 'input'
    prev_C, prev_H, prev_W = C_in, H_in, W_in

    layer_num = 0  # Initialize layer number

    for layer in cnn.net:
        if isinstance(layer, nn.Conv2d):
            layer_num += 1  # Increment layer number
            current_layer_nodes = []

            # Get layer parameters
            in_channels = layer.in_channels
            out_channels = layer.out_channels
            kernel_size = layer.kernel_size
            stride = layer.stride
            padding = layer.padding
            dilation = layer.dilation

            # Compute output dimensions
            H_out = (prev_H + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1
            W_out = (prev_W + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1

            # Create output nodes
            for c_out in range(out_channels):
                for i_out in range(H_out):
                    for j_out in range(W_out):
                        node_idx = neuron_counter
                        neuron_counter += 1
                        current_layer_nodes.append(node_idx)
                        position_to_node_idx[('conv', layer_num, c_out, i_out, j_out)] = node_idx
                        biases[node_idx] = layer.bias.data[c_out].item()
                        activations[node_idx] = None  # Activation applied after this layer

            # Create edges from input to output nodes
            weight = layer.weight.data  # Shape: [out_channels, in_channels, kernel_height, kernel_width]
            for c_out in range(out_channels):
                for i_out in range(H_out):
                    for j_out in range(W_out):
                        output_node_idx = position_to_node_idx[('conv', layer_num, c_out, i_out, j_out)]
                        for c_in in range(in_channels):
                            for k_i in range(kernel_size[0]):
                                for k_j in range(kernel_size[1]):
                                    i_in = i_out * stride[0] - padding[0] + k_i * dilation[0]
                                    j_in = j_out * stride[1] - padding[1] + k_j * dilation[1]
                                    if 0 <= i_in < prev_H and 0 <= j_in < prev_W:
                                        if prev_layer_type == 'input':
                                            input_node_idx = position_to_node_idx.get(
                                                ('input', c_in, i_in, j_in)
                                            )
                                        else:
                                            input_node_idx = position_to_node_idx.get(
                                                (prev_layer_type, prev_layer_num, c_in, i_in, j_in)
                                            )
                                        if input_node_idx is not None:
                                            edge_index[0].append(input_node_idx)
                                            edge_index[1].append(output_node_idx)
                                            w = weight[c_out, c_in, k_i, k_j].item()
                                            edge_weight.append(w)

            prev_layer_nodes = current_layer_nodes
            prev_layer_type = 'conv'
            prev_layer_num = layer_num
            prev_C, prev_H, prev_W = out_channels, H_out, W_out
            layer_neurons.append(current_layer_nodes)

        elif isinstance(layer, nn.ReLU):
            # Set activation function for previous layer nodes
            for idx in prev_layer_nodes:
                activations[idx] = 'relu'

        elif isinstance(layer, nn.MaxPool2d):
            # For now, skip MaxPool2d layers as per your request
            pass

        elif isinstance(layer, nn.Linear):
            layer_num += 1  # Increment layer number
            current_layer_nodes = []

            # Flatten previous layer nodes (if not already flattened)
            input_size = len(prev_layer_nodes)
            output_size = layer.out_features

            # Create output nodes
            current_layer_nodes = list(range(neuron_counter, neuron_counter + output_size))
            neuron_counter += output_size

            # Record biases
            bias = layer.bias.data
            for idx, b in zip(current_layer_nodes, bias):
                biases[idx] = b.item()

            # Record activations (to be set after activation layer)
            for idx in current_layer_nodes:
                activations[idx] = None  # Placeholder

            # Create edges
            weight_matrix = layer.weight.data  # Shape: [out_features, in_features]
            for target_idx, target_neuron in enumerate(current_layer_nodes):
                for source_idx, source_neuron in enumerate(prev_layer_nodes):
                    weight = weight_matrix[target_idx, source_idx].item()
                    edge_index[0].append(source_neuron)
                    edge_index[1].append(target_neuron)
                    edge_weight.append(weight)

            prev_layer_nodes = current_layer_nodes
            prev_layer_type = 'linear'
            prev_layer_num = layer_num
            layer_neurons.append(current_layer_nodes)

        elif isinstance(layer, nn.Flatten):
            # Flattening handled implicitly in Linear layer
            # No action needed
            pass

        else:
            # Handle other layer types if necessary
            pass

    # Convert lists to tensors
    edge_index = torch.tensor(edge_index, dtype=torch.long)
    edge_attr = torch.tensor(edge_weight, dtype=torch.float)

    num_nodes = neuron_counter
    node_bias = torch.zeros(num_nodes, dtype=torch.float)
    for idx, b in biases.items():
        node_bias[idx] = b

    # Activation mapping
    activation_map = {'relu': 1, None: 0}
    node_activation = torch.zeros(num_nodes, dtype=torch.long)
    for idx, act in activations.items():
        node_activation[idx] = activation_map[act]

    # Create the Data object
    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_nodes, name=cnn.name)
    data.bias = node_bias
    data.activation = node_activation

    # Collect all node indices for this CNN
    cnn_node_indices = list(range(num_nodes))

    return data, cnn_node_indices, layer_neurons









def cnn_to_graph_ws(cnn, input_shape):
    """
    Converts a CNN into a graph representation suitable for GNN processing.

    Args:
        cnn (nn.Module): The CNN model to convert.
        input_shape (tuple): The shape of the input (C_in, H_in, W_in).

    Returns:
        data (torch_geometric.data.Data): The graph representation.
        cnn_node_indices (list): List of node indices for the CNN.
        layer_neurons (list): List of node indices per layer.
    """
    import torch
    from torch_geometric.data import Data


    neuron_counter = 0
    edge_index = [[], []]
    edge_weight = []
    biases = {}
    activations = {}
    layer_neurons = []
    position_to_node_idx = {}
    current_layer_nodes = []
    edge_to_kernel_idx = {}
    edge_idx_counter = 0  # To keep track of edge indices
    node_to_layer_idx = {}
    layer_types = []  # Keep track of layer types

    C_in, H_in, W_in = input_shape
    device = next(cnn.parameters()).device

    # Initialize layer numbers
    prev_layer_num = 0  # Input layer number is 0
    layer_num = 0  # Initialize layer number

    # Create input nodes
    for c_in in range(C_in):
        for i in range(H_in):
            for j in range(W_in):
                node_idx = neuron_counter
                neuron_counter += 1
                current_layer_nodes.append(node_idx)
                position_to_node_idx[('input', prev_layer_num, c_in, i, j)] = node_idx  # Include prev_layer_num
                biases[node_idx] = 0.0
                activations[node_idx] = None  # No activation for input nodes
                node_to_layer_idx[node_idx] = 0  # Input layer

    layer_neurons.append(current_layer_nodes)
    layer_types.append('input')

    prev_layer_nodes = current_layer_nodes
    prev_layer_type = 'input'
    prev_C, prev_H, prev_W = C_in, H_in, W_in

    for layer in cnn.net:
        if isinstance(layer, nn.Conv2d):
            layer_num += 1  # Increment layer number
            current_layer_nodes = []

            # Get layer parameters
            in_channels = layer.in_channels
            out_channels = layer.out_channels
            kernel_size = layer.kernel_size
            stride = layer.stride
            padding = layer.padding
            dilation = layer.dilation

            # Ensure parameters are tuples
            if isinstance(kernel_size, int):
                kernel_size = (kernel_size, kernel_size)
            if isinstance(stride, int):
                stride = (stride, stride)
            if isinstance(padding, int):
                padding = (padding, padding)
            if isinstance(dilation, int):
                dilation = (dilation, dilation)

            # Compute output dimensions
            H_out = (prev_H + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1
            W_out = (prev_W + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1

            # Create output nodes
            for c_out in range(out_channels):
                for i_out in range(H_out):
                    for j_out in range(W_out):
                        node_idx = neuron_counter
                        neuron_counter += 1
                        current_layer_nodes.append(node_idx)
                        position_to_node_idx[('conv', layer_num, c_out, i_out, j_out)] = node_idx
                        biases[node_idx] = layer.bias.data[c_out].item()
                        activations[node_idx] = None  # Activation applied after this layer
                        node_to_layer_idx[node_idx] = layer_num

            # Create edges from input to output nodes
            weight = layer.weight.data  # Shape: [out_channels, in_channels, kernel_height, kernel_width]
            for c_out in range(out_channels):
                for i_out in range(H_out):
                    for j_out in range(W_out):
                        output_node_idx = position_to_node_idx[('conv', layer_num, c_out, i_out, j_out)]
                        for c_in in range(in_channels):
                            for k_i in range(kernel_size[0]):
                                for k_j in range(kernel_size[1]):
                                    i_in = i_out * stride[0] - padding[0] + k_i * dilation[0]
                                    j_in = j_out * stride[1] - padding[1] + k_j * dilation[1]
                                    if 0 <= i_in < prev_H and 0 <= j_in < prev_W:
                                        input_node_idx = position_to_node_idx.get(
                                            (prev_layer_type, prev_layer_num, c_in, i_in, j_in)
                                        )
                                        if input_node_idx is not None:
                                            edge_index[0].append(input_node_idx)
                                            edge_index[1].append(output_node_idx)
                                            w = weight[c_out, c_in, k_i, k_j].item()
                                            edge_weight.append(w)

                                            # Map edge to convolutional kernel indices
                                            kernel_idx = (layer_num, c_out, c_in, k_i, k_j)
                                            edge_to_kernel_idx[edge_idx_counter] = kernel_idx
                                            edge_idx_counter += 1

            prev_layer_nodes = current_layer_nodes
            prev_layer_type = 'conv'
            prev_layer_num = layer_num
            prev_C, prev_H, prev_W = out_channels, H_out, W_out
            layer_neurons.append(current_layer_nodes)
            layer_types.append('conv')

        elif isinstance(layer, nn.ReLU):
            # Set activation function for previous layer nodes
            for idx in prev_layer_nodes:
                activations[idx] = 'relu'
            layer_types.append('relu')

        elif isinstance(layer, nn.Flatten):
            layer_types.append('flatten')
            # Flattening is handled implicitly in Linear layers

        elif isinstance(layer, nn.Linear):
            layer_num += 1  # Increment layer number
            current_layer_nodes = []

            # Flatten previous layer nodes
            input_size = len(prev_layer_nodes)
            output_size = layer.out_features

            # Create output nodes
            current_layer_nodes = list(range(neuron_counter, neuron_counter + output_size))
            neuron_counter += output_size

            # Record biases
            bias = layer.bias.data
            for idx, b in zip(current_layer_nodes, bias):
                biases[idx] = b.item()
                node_to_layer_idx[idx] = layer_num

            # Record activations (to be set after activation layer)
            for idx in current_layer_nodes:
                activations[idx] = None  # Placeholder

            # Create edges
            weight_matrix = layer.weight.data  # Shape: [out_features, in_features]
            for target_idx, target_neuron in enumerate(current_layer_nodes):
                for source_idx, source_neuron in enumerate(prev_layer_nodes):
                    weight = weight_matrix[target_idx, source_idx].item()
                    edge_index[0].append(source_neuron)
                    edge_index[1].append(target_neuron)
                    edge_weight.append(weight)  # Store actual weight

                    # Map edge to linear layer indices
                    edge_to_kernel_idx[edge_idx_counter] = {
                        'layer_num': layer_num,
                        'target_idx': target_idx,
                        'source_idx': source_idx
                    }
                    edge_idx_counter += 1

            prev_layer_nodes = current_layer_nodes
            prev_layer_type = 'linear'
            prev_layer_num = layer_num
            layer_neurons.append(current_layer_nodes)
            layer_types.append('linear')

        else:
            # Handle other layer types if necessary
            pass

    # Convert lists to tensors
    edge_index = torch.tensor(edge_index, dtype=torch.long)
    edge_attr = torch.tensor(edge_weight, dtype=torch.float)

    num_nodes = neuron_counter
    node_bias = torch.zeros(num_nodes, dtype=torch.float)
    for idx, b in biases.items():
        node_bias[idx] = b

    # Activation mapping
    activation_map = {'relu': 1, None: 0}
    node_activation = torch.zeros(num_nodes, dtype=torch.long)
    for idx, act in activations.items():
        node_activation[idx] = activation_map[act]

    # Create the Data object
    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_nodes, name=cnn.name)
    data.bias = node_bias
    data.activation = node_activation

    # Collect all node indices for this CNN
    cnn_node_indices = list(range(num_nodes))

    return data, cnn_node_indices, layer_neurons, edge_to_kernel_idx, node_to_layer_idx, layer_types

def unify(model_list, input_shape):
    """
    Unifies multiple disjoint CNNs into a single graph representation.

    Args:
        cnn_list (list): List of CNN models (nn.Module instances).
        input_shape (tuple): The shape of the input (C_in, H_in, W_in).

    Returns:
        data_combined (torch_geometric.data.Data): The combined graph representation.
        cnn_node_indices_list (list of lists): List of node indices for each CNN.
        cnn_layer_neurons_list (list of lists): List of node indices per layer for each CNN.
        cnn_input_indices_list (list of lists): List of input node indices for each CNN.
        cnn_output_indices_list (list of lists): List of output node indices for each CNN.
    """
    node_offset = 0
    total_edge_index = []
    total_edge_attr = []
    total_biases = []
    total_activations = []

    node_indices_list = []
    layer_neurons_list = []
    input_indices_list = []
    output_indices_list = []
    names = []

    for model in model_list:
        if isinstance(model, MLPClassifier):
            data, node_indices, layer_neurons = mlp_to_graph(model)
        elif isinstance(model, CNNClassifier):
            data, node_indices, layer_neurons = cnn_to_graph(model, input_shape)
        else:
            raise ValueError("unsupported model")

        names.append(data.name)

        # num_nodes = data.num_nodes

        # Adjust edge indices to account for previous CNNs
        adjusted_edge_index = data.edge_index + node_offset  # Broadcasting addition
        total_edge_index.append(adjusted_edge_index)

        # Append edge attributes
        total_edge_attr.append(data.edge_attr)

        # Append biases and activations
        total_biases.append(data.bias)
        total_activations.append(data.activation)

        # Record node indices for this CNN
        node_indices_list.append([idx + node_offset for idx in node_indices])

        # Adjust layer neurons
        adjusted_layer_neurons = [[idx + node_offset for idx in layer] for layer in layer_neurons]
        layer_neurons_list.append(adjusted_layer_neurons)

        # Input and output nodes for this CNN
        input_indices = adjusted_layer_neurons[0]
        output_indices = adjusted_layer_neurons[-1]
        input_indices_list.append(input_indices)
        output_indices_list.append(output_indices)

        # Update total number of nodes
        node_offset += data.num_nodes

    # Combine all edge indices and attributes
    combined_edge_index = torch.cat(total_edge_index, dim=1)
    combined_edge_attr = torch.cat(total_edge_attr, dim=0)

    # Combine biases and activations
    combined_biases = torch.cat(total_biases, dim=0)
    combined_activations = torch.cat(total_activations, dim=0)

    # Create the combined Data object
    data_combined = Data(edge_index=combined_edge_index, edge_attr=combined_edge_attr, num_nodes=node_offset, names=names)
    data_combined.bias = combined_biases
    data_combined.activation = combined_activations

    return data_combined, node_indices_list, layer_neurons_list, input_indices_list, output_indices_list


def unify_ws(model_list, input_shape):
    node_offset = 0
    total_edge_index = []
    total_edge_attr = []
    total_biases = []
    total_activations = []

    node_indices_list = []
    layer_neurons_list = []
    layer_types_lists = []
    input_indices_list = []
    output_indices_list = []
    names = []

    total_edge_to_kernel_idx = {}
    total_node_to_layer_idx = {}
    edge_idx_offset = 0

    for model in model_list:
        if isinstance(model, MLPClassifier):
            data, node_indices, layer_neurons, edge_to_kernel_idx, node_to_layer_idx, layer_types = mlp_to_graph_ws(model)
        elif isinstance(model, CNNClassifier) or isinstance(model, CNNClassifierDeep):
            data, node_indices, layer_neurons, edge_to_kernel_idx, node_to_layer_idx, layer_types = cnn_to_graph_ws(model, input_shape)
        else:
            raise ValueError("Unsupported model type")

        names.append(data.name)

        # Adjust edge indices to account for previous models
        adjusted_edge_index = data.edge_index + node_offset
        total_edge_index.append(adjusted_edge_index)

        # Append edge attributes
        total_edge_attr.append(data.edge_attr)

        # Append biases and activations
        total_biases.append(data.bias)
        total_activations.append(data.activation)

        # Record node indices for this model
        node_indices_list.append([idx + node_offset for idx in node_indices])

        # Adjust layer neurons
        adjusted_layer_neurons = [[idx + node_offset for idx in layer] for layer in layer_neurons]
        layer_neurons_list.append(adjusted_layer_neurons)
        layer_types_lists.append(layer_types)

        # Input and output nodes for this model
        input_indices = adjusted_layer_neurons[0]
        output_indices = adjusted_layer_neurons[-1]
        input_indices_list.append(input_indices)
        output_indices_list.append(output_indices)

        # Adjust edge_to_kernel_idx
        adjusted_edge_to_kernel_idx = {}
        for edge_idx, kernel_idx in edge_to_kernel_idx.items():
            adjusted_edge_idx = edge_idx + edge_idx_offset
            adjusted_edge_to_kernel_idx[adjusted_edge_idx] = kernel_idx
        total_edge_to_kernel_idx.update(adjusted_edge_to_kernel_idx)
        edge_idx_offset += data.edge_index.size(1)

        # Adjust node_to_layer_idx
        adjusted_node_to_layer_idx = {idx + node_offset: ln for idx, ln in node_to_layer_idx.items()}
        total_node_to_layer_idx.update(adjusted_node_to_layer_idx)

        # Update total number of nodes
        node_offset += data.num_nodes

    # Combine all edge indices and attributes
    combined_edge_index = torch.cat(total_edge_index, dim=1)
    combined_edge_attr = torch.cat(total_edge_attr, dim=0)

    # Combine biases and activations
    combined_biases = torch.cat(total_biases, dim=0)
    combined_activations = torch.cat(total_activations, dim=0)

    # Create the combined Data object
    data_combined = Data(edge_index=combined_edge_index, edge_attr=combined_edge_attr, num_nodes=node_offset, names=names)
    data_combined.bias = combined_biases
    data_combined.activation = combined_activations

    return data_combined, node_indices_list, layer_neurons_list, layer_types_lists, input_indices_list, output_indices_list, total_edge_to_kernel_idx, total_node_to_layer_idx

def plot_unified_graph(data, node_indices_list, layer_neurons_list):
    """
    Plots the unified graph representation of multiple models.

    Parameters:
    - data: PyTorch Geometric Data object containing the combined graph.
    - node_indices_list: List of node indices for each model.
    - layer_neurons_list: List of layer_neurons lists for each model.
    """
    G = nx.DiGraph()
    edge_index = data.edge_index.cpu().numpy()
    edge_attr = data.edge_attr.cpu().numpy()
    biases = data.bias.cpu().numpy()
    activations = data.activation.cpu().numpy()

    # Total number of models
    num_models = len(layer_neurons_list)

    # Create sets of node indices for each model
    nodes_list = []
    for node_indices in node_indices_list:
        nodes_list.append(set(node_indices))

    # Add nodes with attributes
    for idx in range(data.num_nodes):
        activation = 'ReLU' if activations[idx] == 1 else ''
        G.add_node(idx, bias=f"{biases[idx]:.2f}", activation=activation)

    # Add edges with weights
    for i in range(edge_index.shape[1]):
        src = edge_index[0, i]
        dst = edge_index[1, i]
        weight = edge_attr[i]
        G.add_edge(src, dst, weight=f"{weight:.2f}")

    # Assign positions to nodes based on layers and models
    pos = {}
    y_offset = 0
    vertical_spacing = 2
    horizontal_spacing = 5

    # Colors for models
    color_map = plt.cm.get_cmap('tab10', num_models)

    # Position layers for each model
    for idx, layer_neurons in enumerate(layer_neurons_list):
        x_offset = idx * horizontal_spacing  # Adjust horizontal spacing between models
        for layer_idx, layer in enumerate(layer_neurons):
            y = -layer_idx * vertical_spacing + y_offset
            x_positions = np.linspace(x_offset - 1, x_offset + 1, num=len(layer))
            for x, node in zip(x_positions, layer):
                pos[node] = (x, y)

    # Get edge labels
    edge_labels = nx.get_edge_attributes(G, 'weight')

    # Get node labels
    node_labels = {}
    for idx in G.nodes():
        node_label = f"{idx}\nBias: {G.nodes[idx]['bias']}"
        if G.nodes[idx]['activation']:
            node_label += f"\nAct: {G.nodes[idx]['activation']}"
        node_labels[idx] = node_label

    # Determine node colors based on model membership
    node_colors = []
    for idx in G.nodes():
        found = False
        for idx, nodes in enumerate(nodes_list):
            if idx in nodes:
                node_colors.append(color_map(idx))
                found = True
                break
        if not found:
            node_colors.append('gray')  # Nodes not belonging to any model (should not occur)

    # Determine edge colors based on model membership
    edge_colors = []
    for src, dst in G.edges():
        found = False
        for idx, nodes in enumerate(nodes_list):
            if src in nodes and dst in nodes:
                edge_colors.append(color_map(idx))
                found = True
                break
        if not found:
            edge_colors.append('gray')

    # Draw the graph
    plt.figure(figsize=(15, 10))
    nx.draw(G, pos, with_labels=False, node_size=800, node_color=node_colors, edge_color=edge_colors, arrows=True)
    nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=6)
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)
    plt.axis('off')
    plt.title('Unified Graph Visualization')

    plt.show()


def to_networkx_with_attrs(data):
    """
    Converts torch_geometric.data.Data to networkx.Graph, including node and edge attributes.

    Parameters:
    - data: torch_geometric.data.Data

    Returns:
    - G: networkx.Graph
    """
    G = nx.DiGraph()  # Use a directed graph since MLPs are directional

    # Add nodes with attributes
    for i in range(data.num_nodes):
        G.add_node(i)
        # Optionally, add node attributes like bias or activation
        G.nodes[i]['bias'] = data.bias[i].item()
        G.nodes[i]['activation'] = data.activation[i].item()

    # Add edges with attributes
    edge_index = data.edge_index.cpu().numpy()
    edge_attr = data.edge_attr.cpu().numpy()
    for idx in range(edge_index.shape[1]):
        src = edge_index[0, idx]
        tgt = edge_index[1, idx]
        weight = edge_attr[idx]
        G.add_edge(src, tgt, weight=weight.item())

    return G

# @torch.no_grad()
# def test_forward():
#     models = [CNNClassifier(), MLPClassifier(28*28, [5], 10), MLPClassifier(28*28, [5, 2], 10), CNNClassifier()]

#     device = "cuda" if torch.cuda.is_available() else "cpu"
#     input_shape = (1, 28, 28)
#     batch_shape = (1, *input_shape)
#     data, node_indices_list, layer_neurons_list, input_indices_list, output_indices_list = unify(models, input_shape)
#     test_sample = torch.rand(batch_shape).to(device)
#     logger.info(f"{test_sample.shape=}")

#     model2cluster = {i:i for i in range(len(models))}

#     ugnn = UGNN(
#         data,
#         layer_neurons_list,
#         input_indices_list,
#         model2cluster,
#         device,
#         k_edge_theta=100000000,
#         k_bias_theta=100000000,
#         act="relu",
#         scale=1
#     ).to(device)
#     ugnn.eval()

#     with torch.no_grad():
#         ugnn.theta_edge.fill_(1.0)
#         ugnn.theta_bias.fill_(1.0)

#     model_outputs = []
#     for model in models:
#         model = model.to(device)
#         model.eval()
#         model_outputs.append(model(test_sample))

#     ugnn_outputs = ugnn([(test_sample, None) for _ in range(len(models))])

#     for model_output, ugnn_output in zip(model_outputs, ugnn_outputs):
#         logger.info(f"Diff: {torch.abs(model_output - ugnn_output).max().item()}")


# test_forward()

@torch.no_grad()
def test_forward_ws():
    models = [CNNClassifierDeep(in_channels=3, num_classes=7), CNNClassifierDeep(in_channels=3, num_classes=7)]

    device = "cuda" if torch.cuda.is_available() else "cpu"
    input_shape = (3, 28, 28)
    batch_shape = (5, *input_shape)
    results = unify_ws(models, input_shape)
    (data, node_indices_list, layer_neurons_list, layer_types_lists, input_indices_list, output_indices_list, edge_to_kernel_idx, node_to_layer_idx) = results
    # plot_unified_graph(data, node_indices_list, layer_neurons_list)
    print(data)
    test_sample = torch.rand(batch_shape).to(device)
    logger.info(f"{test_sample.shape=}")

    model2cluster = {i:i for i in range(len(models))}

    ugnn = UGNN_WS(
        data,
        layer_neurons_list,
        layer_types_lists,  # Pass layer_types_lists
        input_indices_list,
        model2cluster,
        device,
        edge_to_kernel_idx,
        node_to_layer_idx,
        k_edge_theta=500000,
        k_bias_theta=200000,
        act="relu",
        scale=1
    ).to(device)
    ugnn.eval()

    print(ugnn.edge_groups)
    print(ugnn.k_edge_theta)
    print(ugnn.k_bias_theta)

    with torch.no_grad():
        ugnn.theta_edge.fill_(1.0)
        ugnn.theta_bias.fill_(1.0)

    model_outputs = []
    for model in models:
        model = model.to(device)
        model.eval()
        model_outputs.append(model(test_sample))

    ugnn_outputs = ugnn([(test_sample, None) for _ in range(len(models))])

    for idx, (model_output, ugnn_output) in enumerate(zip(model_outputs, ugnn_outputs)):
        max_diff = torch.abs(model_output - ugnn_output).max().item()
        logger.info(f"Model {idx} Diff: {max_diff}")

test_forward_ws()

# gen=torch.Generator()
# gen.manual_seed(seed)
# models = [MLPClassifier(4, [5], 10, generator=gen)]

# data, node_indices_list, layer_neurons_list, input_indices_list, output_indices_list = unify(models, (1, 2, 2))

# logger.info(f"{data=}")
# logger.info(f"{node_indices_list=}")
# logger.info(f"{layer_neurons_list=}")
# logger.info(f"{input_indices_list=}")
# logger.info(f"{output_indices_list=}")

# plot_unified_graph(data, node_indices_list, layer_neurons_list)

# ugnn = UGNN(
#     data,
#     layer_neurons_list,
#     input_indices_list,
#     model2cluster,
#     device,
#     k_edge_theta=500000,
#     k_bias_theta=200000,
#     act="relu",
#     scale=1
# ).to(device)

# print(ugnn.k_edge_theta)
# print(ugnn.k_bias_theta)
# print(ugnn.edge_groups)
# print(ugnn.edge_groups.shape)

gen=torch.Generator()
gen.manual_seed(seed)
models = [CNNClassifier(in_channels=1, num_classes=2, generator=gen)]
print(models)

data, node_indices_list, layer_neurons_list, layer_types_lists, input_indices_list, output_indices_list, edge_to_kernel_idx, node_to_layer_idx = unify_ws(models, (1, 2, 2))

logger.info(f"{data=}")
logger.info(f"{node_indices_list=}")
logger.info(f"{layer_neurons_list=}")
logger.info(f"{layer_types_lists=}")
logger.info(f"{input_indices_list=}")
logger.info(f"{output_indices_list=}")
logger.info(f"{edge_to_kernel_idx=}")
logger.info(f"{node_to_layer_idx=}")

# plot_unified_graph(data, node_indices_list, layer_neurons_list)

# ugnn = UGNN_WS(
#     data,
#     layer_neurons_list,
#     layer_types_lists,  # Pass layer_types_lists
#     input_indices_list,
#     model2cluster,
#     device,
#     edge_to_kernel_idx,
#     node_to_layer_idx,
#     k_edge_theta=500000,
#     k_bias_theta=200000,
#     act="relu",
#     scale=1
# ).to(device)

# print(ugnn.k_edge_theta)
# print(ugnn.k_bias_theta)
# print(ugnn.edge_to_kernel_idx)
# print(ugnn.edge_groups)
# print(ugnn.edge_groups.shape)



# device = "cuda" if torch.cuda.is_available() else "cpu"

# model2cluster = {i:i for i in range(len(models))}
# ugnn = UGNN(
#     data,
#     layer_neurons_list,
#     input_indices_list,
#     model2cluster,
#     device,
#     k_edge_theta=100000000,
#     k_bias_theta=100000000,
#     act="relu",
#     scale=1
# ).to(device)

# plot_unified_graph(data, node_indices_list, layer_neurons_list)

@torch.no_grad()
def evaluate_unified_gnn(model, data_loader, num_models, device):
    model.eval()
    all_labels = []
    all_predictions_list = [[] for _ in range(num_models)]
    total_loss = 0
    criterion = torch.nn.CrossEntropyLoss()

    for images, labels in tqdm(data_loader, desc="Validating"):
        images = images.to(device)
        labels = labels.to(device)
        outputs = model([(images, labels) for _ in range(num_models)])
        losses = [criterion(output, labels) for output in outputs]
        loss = sum(losses) / num_models
        total_loss += loss.item()
        for idx, output in enumerate(outputs):
            _, predicted = torch.max(output.data, 1)
            all_predictions_list[idx].extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    metrics_list = []
    for idx in range(num_models):
        all_predictions = all_predictions_list[idx]
        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')
        metrics_list.append((precision, recall, f1))

    avg_loss = total_loss / len(data_loader)
    return metrics_list, avg_loss

import torch.nn.functional as F

def train_unified_gnn(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    num_epochs,
    device,
    num_models,
    model2cluster,
    scheduler_patience,
    validate_every_epoch,
    weight_save_path,
    early_stopping_patience,
    metrics_save_file,
    alpha,
    lr_decay_factor=0.1,  # Factor to reduce learning rate by
    min_lr=1e-6,  # Minimum learning rate
):
    model.to(device)
    model.train()
    training_losses = []
    val_losses = []
    val_prec = []
    val_rec = []
    val_f1 = []

    # Initialize best F1 scores for each model
    best_f1s = [0.0] * num_models
    best_avg_f1 = 0.0

    epochs_no_improve = 0
    scheduler_epochs_no_improve = 0  # Patience counter for scheduler

    # Get initial learning rate
    for param_group in optimizer.param_groups:
        initial_lr = param_group["lr"]
        break

    current_lr = initial_lr

    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode="min")

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        for batch in tqdm(
            train_loader, desc=f"Training Epoch {epoch + 1}/{num_epochs}"
        ):
            # batch = {0: batch, 1: batch, 2: batch}
            optimizer.zero_grad()
            outputs = model(batch)  # List of outputs
            labels = [
                batch[model2cluster[model_idx]][1] for model_idx in range(num_models)
            ]

            losses = [
                criterion(output, label.to(device))
                for output, label in zip(outputs, labels)
            ]

            # Extract scalar loss values
            with torch.no_grad():
                loss_values = torch.tensor(
                    [loss.item() for loss in losses], device=device
                )

            # Optional: Clamp loss values to prevent numerical instability
            loss_values = torch.clamp(loss_values, min=1e-8, max=10.0)

            # # Compute weights proportional to losses raised to power alpha
            # weights = loss_values ** model.alpha
            # total_weight = weights.sum()
            # weights = weights / (total_weight + 1e-8)  # Normalize weights to sum to 1

            # # Compute weighted average loss
            # loss = sum(w * l for w, l in zip(weights, losses))

            # loss_weights = torch.softmax(model.model_loss_weights, dim=0)
            # loss = sum(w * l for w, l in zip(loss_weights, losses))

            loss = sum(losses) / num_models

            # Proceed with backpropagation
            loss.backward()

            # torch.nn.utils.clip_grad_norm_(
            #     [model.theta_edge, model.theta_bias], max_norm=1.0
            # )

            optimizer.step()

            model.update_buffers()

            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        training_losses.append(avg_loss)

        scheduler.step(min(training_losses))

        logger.info(
            f"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_loss:.4f}, LR: {current_lr}, LW: {torch.softmax(model.model_loss_weights, dim=0)}, Edge Act Scale: {model.theta_edge_act_scale.item()}, Bias Act Scale: {model.theta_bias_act_scale.item()}, Alpha: {model.alpha}"
        )

        if (epoch + 1) % validate_every_epoch == 0:
            val_metrics, avg_val_loss = evaluate_unified_gnn(
                model, val_loader, num_models=num_models, device=device
            )

            val_losses.append(avg_val_loss)

            current_f1s = []  # Collect current F1 scores for all models
            any_model_improved = False  # Flag to check if any model improved this epoch

            for idx, metrics in enumerate(val_metrics):
                precision, recall, f1 = metrics
                logger.info(
                    f"Epoch [{epoch + 1}/{num_epochs}], Validation uGNN Model#{idx + 1} - Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}, Best F1: {best_f1s[idx]:.4f}"
                )

                # Check if current model improved
                if f1 > best_f1s[idx]:
                    best_f1s[idx] = f1
                    any_model_improved = True

                    # Save the data for the model with improved F1
                    data_save_path = f"{weight_save_path}_graph_{idx + 1}_best_f1.pt"
                    logger.info(
                        f"Epoch [{epoch + 1}/{num_epochs}] Saving data at {data_save_path}"
                    )
                    torch.save(
                        {
                            "data": model.data,
                            "edge_attr": model.edge_attr,
                            "biases": model.biases,
                        },
                        data_save_path,
                    )

                val_prec.append((idx, precision))
                val_rec.append((idx, recall))
                val_f1.append((idx, f1))
                current_f1s.append(f1)

            # Check if any model improved
            if any_model_improved:
                epochs_no_improve = 0  # Reset early stopping patience counter
                scheduler_epochs_no_improve = 0  # Reset scheduler patience counter
            else:
                epochs_no_improve += 1
                scheduler_epochs_no_improve += 1

            # Update the best maximum F1 score
            avg_f1 = sum(current_f1s) / len(current_f1s)
            logger.info(f"Epoch [{epoch + 1}/{num_epochs}], Avg F1: {avg_f1:.4f} Best Avg F1: {best_avg_f1:.4f}")
            if avg_f1 > best_avg_f1:
                best_avg_f1 = avg_f1

                # Save the model's state dict and data
                logger.info(
                    f"Epoch [{epoch + 1}/{num_epochs}] Found best avg F1 {avg_f1} Saving weights at {weight_save_path}.pt"
                )
                torch.save(model.state_dict(), weight_save_path + ".pt")

            # Early stopping
            if epochs_no_improve >= early_stopping_patience:
                logger.info(
                    f"Early stopping at epoch {epoch + 1} due to no improvement in validation F1 for {early_stopping_patience} epochs."
                )
                break

            # # Learning rate scheduler
            # if scheduler_epochs_no_improve >= scheduler_patience:
            #     # Reduce learning rate
            #     new_lr = current_lr * lr_decay_factor
            #     new_lr = max(
            #         new_lr, min_lr
            #     )  # Ensure the learning rate doesn't go below min_lr

            #     if new_lr < current_lr:
            #         logger.info(
            #             f"Epoch [{epoch + 1}/{num_epochs}] Reducing learning rate from {current_lr:.6f} to {new_lr:.6f}"
            #         )
            #         for param_group in optimizer.param_groups:
            #             param_group["lr"] = new_lr
            #         current_lr = new_lr
            #     else:
            #         logger.info(
            #             f"Epoch [{epoch + 1}/{num_epochs}] Learning rate already at minimum value {current_lr:.6f}"
            #         )

            #     scheduler_epochs_no_improve = 0  # Reset scheduler patience counter

    # Save losses and validation metrics to a JSON file
    with open(metrics_save_file, "w") as f:
        logger.info(f"***********Saving to {metrics_save_file}")
        json.dump(
            {
                "training_losses": training_losses,
                "val_losses": val_losses,
                "val_prec": val_prec,
                "val_rec": val_rec,
                "val_f1": val_f1,
                "best_f1s": best_f1s,
                "best_avg_f1": best_avg_f1
            },
            f,
        )

    return training_losses, val_losses, val_prec, val_rec, val_f1

@torch.no_grad()
def test_unified_gnn(
    model,
    test_loader,
    device,
    num_mlps,
):
    model.to(device)
    model.eval()

    val_metrics, _ = evaluate_unified_gnn(
        model, test_loader, num_models=num_mlps, device=device
    )

    for idx, metrics in enumerate(val_metrics):
        precision, recall, f1 = metrics
        logger.info(
            f"Testing uGNN Model#{idx + 1} - Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}"
        )

# root_dir = "."

# mnist_tr = MNISTLike(root_dir, split="train")
# mnist_val = MNISTLike(root_dir, split="val")
# mnist_ts = MNISTLike(root_dir, split="test")

# i = 5426
# plt.imshow(mnist_tr[i][0][0]), mnist_tr[i][2]

# mnist_tr[0][2]

# root_dir = "."

# mnist_tr = MNISTLike(root_dir, split="train")
# mnist_val = MNISTLike(root_dir, split="val")
# mnist_ts = MNISTLike(root_dir, split="test")


# cluster2model = {
#     0: 0,  # Perturbation 0 assigned to MLP 0
#     1: 1,  # Perturbation 1 assigned to MLP 1
# }

# model2cluster = {v:k for k,v in cluster2model.items()}

# print(mnist_tr[0][1])

# len(mnist_tr), len(mnist_val), len(mnist_ts)

# tr_ds = MorphoMNISTDistShiftDataset(mnist_tr, cluster2model)
# val_ds = MixedPerturbationDataset(mnist_val)
# ts_ds = MixedPerturbationDataset(mnist_ts)



batch_size = 1024

data_generator=torch.Generator()
data_generator.manual_seed(seed)

train_loader = DataLoader(
    med_mnist_dist_shift_tr,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=multi_mlp_collate_fn,
    generator=data_generator
)

val_loader = DataLoader(
    med_mnist_val,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator

)
test_loader = DataLoader(
    med_mnist_test,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator
)

generator = torch.Generator()
generator.manual_seed(seed)

models = [
    CNNClassifierDeep(generator=generator, in_channels=3, num_classes=9),
    CNNClassifier(generator=generator, in_channels=3, num_classes=9),
    MLPClassifier(3*28*28, [100, 50, 20], 9, generator=generator),
    # MLPClassifier(1*28*28, [50], 2, generator=generator),
]

for model in models:
    logger.info(f"{model}, {count_learnable_parameters(model)}")
    for a, b in model.named_parameters():
        print(a, b.sum(), b.shape)

# data, node_indices_list, layer_neurons_list, input_indices_list, output_indices_list = unify(models, (1, 28, 28))
# data

results = unify_ws(models, (3, 28, 28))
(data, node_indices_list, layer_neurons_list, layer_types_lists, input_indices_list, output_indices_list, edge_to_kernel_idx, node_to_layer_idx) = results

data

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

# scale = 1.5
# alpha = 5
# k_edge_theta=99999999999
# k_bias_theta=99999999999
# act = "softsign"

# unified_gnn = UGNN(
#     data,
#     layer_neurons_list,
#     input_indices_list,
#     model2cluster,
#     device=device,
#     k_edge_theta=k_edge_theta,
#     k_bias_theta=k_bias_theta,
#     act=act,
#     scale=scale,
# ).to(device)

# count_learnable_parameters(unified_gnn)

scale = 1.5
alpha = 5
k_edge_theta=50000000
k_bias_theta=10000000
act = "softsign"

model2cluster = {i:i for i in range(len(models))}

unified_gnn = UGNN_WS(
    data,
    layer_neurons_list,
    layer_types_lists,  # Pass layer_types_lists
    input_indices_list,
    model2cluster,
    device,
    edge_to_kernel_idx,
    node_to_layer_idx,
    k_edge_theta=k_edge_theta,
    k_bias_theta=k_bias_theta,
    act=act,
    scale=scale,
).to(device)

count_learnable_parameters(unified_gnn)

# scale = 1.5
# alpha = 5
# k_edge_theta=5000
# k_bias_theta=1000
# act = "softsign"

# unified_gnn = UGNNModelSpecific(
#     data,
#     node_indices_list,
#     layer_neurons_list,
#     input_indices_list,
#     model2cluster,
#     device,
#     k_edge_theta=k_edge_theta,
#     k_bias_theta=k_bias_theta,
#     act=act,
#     scale=scale,
# ).to(device)

# count_learnable_parameters(unified_gnn)

optimizer = optim.AdamW(unified_gnn.parameters(), lr=0.05)
criterion = nn.CrossEntropyLoss()

training_losses, val_losses, val_prec, val_rec, val_f1 = train_unified_gnn(unified_gnn, train_loader, val_loader, criterion, optimizer,
                                                                           num_epochs=2000,
                                                                           device=device,
                                                                           num_models=len(models),
                                                                           model2cluster=model2cluster,
                                                                           scheduler_patience=50,
                                                                           validate_every_epoch=1,
                                                                           weight_save_path=os.path.join(prefix, "ugnn2"),
                                                                           early_stopping_patience=100,
                                                                           metrics_save_file=os.path.join(prefix, f"cnns2,act={act},alpha={alpha},scale={scale},k_edge_theta={k_edge_theta},k_bias_theta={k_bias_theta}.json"),
                                                                           alpha=alpha)

!ls drive/

# comic
fold

!cp ugnn_graph_1_best_f1.pt drive/MyDrive/ugnn_graph_1_best_f1.pt
!cp ugnn_graph_2_best_f1.pt drive/MyDrive/ugnn_graph_2_best_f1.pt
!cp ugnn_graph_3_best_f1.pt drive/MyDrive/ugnn_graph_3_best_f1.pt

batch_size = 1024

data_generator=torch.Generator()
data_generator.manual_seed(seed)

train_loader = DataLoader(
    med_mnist_dist_shift_tr,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=multi_mlp_collate_fn,
    generator=data_generator
)

val_loader = DataLoader(
    med_mnist_val,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator

)
test_loader = DataLoader(
    med_mnist_test,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator
)

mdl_idx = 2
mlp_weights = torch.load(f"ugnn_graph_{mdl_idx}_best_f1.pt")

with torch.no_grad():
    # Update edge_attr buffer
    unified_gnn.edge_attr.copy_(mlp_weights["edge_attr"].to(unified_gnn.edge_attr.device))
    # Update biases buffer
    unified_gnn.biases.copy_(mlp_weights["biases"].to(unified_gnn.biases.device))
    unified_gnn.data = mlp_weights["data"]

test_unified_gnn(unified_gnn, test_loader, device, num_mlps=len(models))

@torch.no_grad()
def evaluate_model(model, data_loader, device):
    model.eval()
    all_labels = []
    all_predictions = []
    total_loss = 0
    criterion = torch.nn.CrossEntropyLoss()

    for images, labels in tqdm(data_loader, desc="Validating"):
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        all_labels.extend(labels.cpu().numpy())
        all_predictions.extend(predicted.cpu().numpy())

    # Compute precision, recall, F1 score
    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')

    # Average loss
    avg_loss = total_loss / len(data_loader)

    return precision, recall, f1, avg_loss, all_predictions, all_labels

def train_model(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    num_epochs,
    scheduler_patience,
    validate_every_epoch,
    early_stopping_patience,
    weight_save_path,
    device,
    cluster,
    metrics_save_path,
):

    model.to(device)
    model.train()
    training_losses = []
    val_losses = []
    val_prec = []
    val_rec = []
    val_f1 = []
    scheduler = lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="max", factor=0.1, patience=scheduler_patience, min_lr=1e-6
    )

    best_f1 = 0
    epochs_no_improve = 0

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0

        for batch in tqdm(
            train_loader, desc=f"Training Epoch {epoch + 1}/{num_epochs}"
        ):
            images, labels = batch[cluster]
            images = images.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
        avg_loss = total_loss / len(train_loader)
        training_losses.append(avg_loss)

        for param_group in optimizer.param_groups:
            current_lr = param_group["lr"]
            break

        logger.info(
            f"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_loss:.4f}, LR: {current_lr}"
        )

        if (epoch + 1) % validate_every_epoch == 0:
            prec, rec, f1, avg_val_loss, _, _ = evaluate_model(model, val_loader, device)
            logger.info(
                f"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Prec: {prec:.4f}, Validation Rec: {rec:.4f}, Validation F1: {f1:.4f}, Best Validation F1: {best_f1:.4f}"
            )
            val_losses.append(avg_val_loss)
            val_prec.append(prec)
            val_rec.append(rec)
            val_f1.append(f1)

            if f1 > best_f1:
                best_f1 = f1
                epochs_no_improve = 0
                logger.info(
                    f"Epoch [{epoch + 1}/{num_epochs}] Saving weights at {weight_save_path}.pt"
                )
                torch.save(model.state_dict(), weight_save_path)

            else:
                epochs_no_improve += 1

            if epochs_no_improve >= early_stopping_patience:
                logger.info(
                    f"Early stopping at epoch {epoch + 1} due to no improvement in validation F1 for {early_stopping_patience} epochs."
                )
                break

            scheduler.step(f1)

    with open(metrics_save_path, "w") as f:
        logger.info(f"******* Saving to {metrics_save_path}")
        json.dump(
            {
                "training_losses": training_losses,
                "val_losses": val_losses,
                "val_prec": val_prec,
                "val_rec": val_rec,
                "val_f1": val_f1,
                "best_f1": best_f1
            }, f
        )

    return training_losses, val_losses, val_prec, val_rec, val_f1

batch_size = 1024

data_generator=torch.Generator()
data_generator.manual_seed(seed)

train_loader = DataLoader(
    med_mnist_dist_shift_tr,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=multi_mlp_collate_fn,
    generator=data_generator
)

val_loader = DataLoader(
    med_mnist_val,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator

)
test_loader = DataLoader(
    med_mnist_test,
    batch_size=batch_size,
    shuffle=False,
    generator=data_generator
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

import copy

model_idx = 2
cluster = model2cluster[model_idx]
model = copy.deepcopy(models[model_idx]).to(device)



criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.05)
train_model(model, train_loader, val_loader, criterion, optimizer,
        num_epochs=2000,
        scheduler_patience=50,
        validate_every_epoch=1,
        early_stopping_patience=100,
        weight_save_path=os.path.join(prefix, f"model_{model_idx}_weigths"),
        device=device,
        cluster=cluster,
        metrics_save_path=os.path.join(prefix, f"model={model},cluster={cluster},model_idx={model_idx}"))

model_idx = 3
logger.info(f"Testing model {model_idx}")

model.load_state_dict(torch.load(f"model_{model_idx}_weigths"))


p,r,f,_,_,_ = evaluate_model(model, test_loader, device)
p,r,f





d = next(iter(train_loader))

plt.imshow(d[0][0][1998][0].numpy())

a = tr_ds[3]

tr_ds[15921]

plt.imshow(a[2][0][0]), a[2][1]

